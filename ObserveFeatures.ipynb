{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/lucia/phd_work/Clpsy/'\n",
    "#path = '/home/lucia/phd_work/shareTask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245388\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>postingFrequency</th>\n",
       "      <th>postingInterval</th>\n",
       "      <th>generalMoreFreq</th>\n",
       "      <th>generalWordCount</th>\n",
       "      <th>healthPostingFrequency</th>\n",
       "      <th>healthPostingInterval</th>\n",
       "      <th>healthMoreFreq</th>\n",
       "      <th>healthWordCount</th>\n",
       "      <th>mentionMethods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>22006</td>\n",
       "      <td>44</td>\n",
       "      <td>23.279070</td>\n",
       "      <td>0</td>\n",
       "      <td>104.312500</td>\n",
       "      <td>3</td>\n",
       "      <td>159.5</td>\n",
       "      <td>0</td>\n",
       "      <td>254.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22014</td>\n",
       "      <td>27</td>\n",
       "      <td>38.038462</td>\n",
       "      <td>1</td>\n",
       "      <td>31.208333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>22015</td>\n",
       "      <td>20</td>\n",
       "      <td>57.368421</td>\n",
       "      <td>1</td>\n",
       "      <td>58.727273</td>\n",
       "      <td>3</td>\n",
       "      <td>379.5</td>\n",
       "      <td>0</td>\n",
       "      <td>149.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22023</td>\n",
       "      <td>138</td>\n",
       "      <td>11.992701</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0</td>\n",
       "      <td>114.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  user_id  postingFrequency  postingInterval  generalMoreFreq  \\\n",
       "1           1    22006                44        23.279070                0   \n",
       "2           2    22014                27        38.038462                1   \n",
       "3           3    22015                20        57.368421                1   \n",
       "4           4    22023               138        11.992701                0   \n",
       "\n",
       "   generalWordCount  healthPostingFrequency  healthPostingInterval  \\\n",
       "1        104.312500                       3                  159.5   \n",
       "2         31.208333                       0                    0.0   \n",
       "3         58.727273                       3                  379.5   \n",
       "4          1.000000                       5                  147.0   \n",
       "\n",
       "   healthMoreFreq  healthWordCount  mentionMethods  \n",
       "1               0           254.25               1  \n",
       "2               0             0.00               0  \n",
       "3               0           149.75               1  \n",
       "4               0           114.00               1  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqFea = pd.read_csv(path + 'suicideDetection/features/FreqFea.csv')\n",
    "print(freqFea.size)\n",
    "freqFea[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#labels = pd.read_csv('/Users/lucia/phd_work/ClpsyData/clpsych19_training_data/crowd_train.csv')\n",
    "labels = pd.read_csv(path+ 'data/clpsych19_training_data/crowd_train.csv' )\n",
    "#assign e to control class\n",
    "labels = labels.fillna('e')\n",
    "#print(labels.shape)\n",
    "allF = pd.merge(freqFea, labels, on = 'user_id',how = 'right')\n",
    "allF.to_csv( path +'suicideDetection/ObserveFea.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>postingFrequency</th>\n",
       "      <th>postingInterval</th>\n",
       "      <th>generalMoreFreq</th>\n",
       "      <th>generalWordCount</th>\n",
       "      <th>healthPostingFrequency</th>\n",
       "      <th>healthPostingInterval</th>\n",
       "      <th>healthMoreFreq</th>\n",
       "      <th>healthWordCount</th>\n",
       "      <th>mentionMethods</th>\n",
       "      <th>raw_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.745280</td>\n",
       "      <td>-0.069840</td>\n",
       "      <td>0.102042</td>\n",
       "      <td>0.020017</td>\n",
       "      <td>0.210650</td>\n",
       "      <td>-0.287045</td>\n",
       "      <td>-0.217641</td>\n",
       "      <td>-0.278780</td>\n",
       "      <td>-0.315687</td>\n",
       "      <td>-0.431874</td>\n",
       "      <td>0.871057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>-0.745280</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053708</td>\n",
       "      <td>-0.123311</td>\n",
       "      <td>-0.052610</td>\n",
       "      <td>-0.190941</td>\n",
       "      <td>0.244540</td>\n",
       "      <td>0.243528</td>\n",
       "      <td>0.256826</td>\n",
       "      <td>0.334215</td>\n",
       "      <td>0.437470</td>\n",
       "      <td>-0.863848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postingFrequency</th>\n",
       "      <td>-0.069840</td>\n",
       "      <td>0.053708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.217545</td>\n",
       "      <td>-0.160764</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>0.207535</td>\n",
       "      <td>0.094307</td>\n",
       "      <td>0.119960</td>\n",
       "      <td>0.088490</td>\n",
       "      <td>0.052350</td>\n",
       "      <td>-0.051934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postingInterval</th>\n",
       "      <td>0.102042</td>\n",
       "      <td>-0.123311</td>\n",
       "      <td>-0.217545</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.156914</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>-0.129792</td>\n",
       "      <td>-0.050716</td>\n",
       "      <td>-0.070599</td>\n",
       "      <td>-0.124361</td>\n",
       "      <td>-0.036222</td>\n",
       "      <td>0.118072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalMoreFreq</th>\n",
       "      <td>0.020017</td>\n",
       "      <td>-0.052610</td>\n",
       "      <td>-0.160764</td>\n",
       "      <td>0.156914</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.060410</td>\n",
       "      <td>-0.105823</td>\n",
       "      <td>-0.056529</td>\n",
       "      <td>-0.019006</td>\n",
       "      <td>-0.050714</td>\n",
       "      <td>-0.057623</td>\n",
       "      <td>0.031912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalWordCount</th>\n",
       "      <td>0.210650</td>\n",
       "      <td>-0.190941</td>\n",
       "      <td>-0.002760</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>-0.060410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.043440</td>\n",
       "      <td>-0.015375</td>\n",
       "      <td>-0.053404</td>\n",
       "      <td>-0.067816</td>\n",
       "      <td>-0.105905</td>\n",
       "      <td>0.241434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthPostingFrequency</th>\n",
       "      <td>-0.287045</td>\n",
       "      <td>0.244540</td>\n",
       "      <td>0.207535</td>\n",
       "      <td>-0.129792</td>\n",
       "      <td>-0.105823</td>\n",
       "      <td>-0.043440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111994</td>\n",
       "      <td>0.450643</td>\n",
       "      <td>0.281709</td>\n",
       "      <td>0.305542</td>\n",
       "      <td>-0.273528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthPostingInterval</th>\n",
       "      <td>-0.217641</td>\n",
       "      <td>0.243528</td>\n",
       "      <td>0.094307</td>\n",
       "      <td>-0.050716</td>\n",
       "      <td>-0.056529</td>\n",
       "      <td>-0.015375</td>\n",
       "      <td>0.111994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141597</td>\n",
       "      <td>0.439995</td>\n",
       "      <td>0.237163</td>\n",
       "      <td>-0.281528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthMoreFreq</th>\n",
       "      <td>-0.278780</td>\n",
       "      <td>0.256826</td>\n",
       "      <td>0.119960</td>\n",
       "      <td>-0.070599</td>\n",
       "      <td>-0.019006</td>\n",
       "      <td>-0.053404</td>\n",
       "      <td>0.450643</td>\n",
       "      <td>0.141597</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>0.266511</td>\n",
       "      <td>-0.285577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthWordCount</th>\n",
       "      <td>-0.315687</td>\n",
       "      <td>0.334215</td>\n",
       "      <td>0.088490</td>\n",
       "      <td>-0.124361</td>\n",
       "      <td>-0.050714</td>\n",
       "      <td>-0.067816</td>\n",
       "      <td>0.281709</td>\n",
       "      <td>0.439995</td>\n",
       "      <td>0.303944</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.239671</td>\n",
       "      <td>-0.383654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentionMethods</th>\n",
       "      <td>-0.431874</td>\n",
       "      <td>0.437470</td>\n",
       "      <td>0.052350</td>\n",
       "      <td>-0.036222</td>\n",
       "      <td>-0.057623</td>\n",
       "      <td>-0.105905</td>\n",
       "      <td>0.305542</td>\n",
       "      <td>0.237163</td>\n",
       "      <td>0.266511</td>\n",
       "      <td>0.239671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.509683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_label</th>\n",
       "      <td>0.871057</td>\n",
       "      <td>-0.863848</td>\n",
       "      <td>-0.051934</td>\n",
       "      <td>0.118072</td>\n",
       "      <td>0.031912</td>\n",
       "      <td>0.241434</td>\n",
       "      <td>-0.273528</td>\n",
       "      <td>-0.281528</td>\n",
       "      <td>-0.285577</td>\n",
       "      <td>-0.383654</td>\n",
       "      <td>-0.509683</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Unnamed: 0   user_id  postingFrequency  \\\n",
       "Unnamed: 0                1.000000 -0.745280         -0.069840   \n",
       "user_id                  -0.745280  1.000000          0.053708   \n",
       "postingFrequency         -0.069840  0.053708          1.000000   \n",
       "postingInterval           0.102042 -0.123311         -0.217545   \n",
       "generalMoreFreq           0.020017 -0.052610         -0.160764   \n",
       "generalWordCount          0.210650 -0.190941         -0.002760   \n",
       "healthPostingFrequency   -0.287045  0.244540          0.207535   \n",
       "healthPostingInterval    -0.217641  0.243528          0.094307   \n",
       "healthMoreFreq           -0.278780  0.256826          0.119960   \n",
       "healthWordCount          -0.315687  0.334215          0.088490   \n",
       "mentionMethods           -0.431874  0.437470          0.052350   \n",
       "raw_label                 0.871057 -0.863848         -0.051934   \n",
       "\n",
       "                        postingInterval  generalMoreFreq  generalWordCount  \\\n",
       "Unnamed: 0                     0.102042         0.020017          0.210650   \n",
       "user_id                       -0.123311        -0.052610         -0.190941   \n",
       "postingFrequency              -0.217545        -0.160764         -0.002760   \n",
       "postingInterval                1.000000         0.156914          0.089300   \n",
       "generalMoreFreq                0.156914         1.000000         -0.060410   \n",
       "generalWordCount               0.089300        -0.060410          1.000000   \n",
       "healthPostingFrequency        -0.129792        -0.105823         -0.043440   \n",
       "healthPostingInterval         -0.050716        -0.056529         -0.015375   \n",
       "healthMoreFreq                -0.070599        -0.019006         -0.053404   \n",
       "healthWordCount               -0.124361        -0.050714         -0.067816   \n",
       "mentionMethods                -0.036222        -0.057623         -0.105905   \n",
       "raw_label                      0.118072         0.031912          0.241434   \n",
       "\n",
       "                        healthPostingFrequency  healthPostingInterval  \\\n",
       "Unnamed: 0                           -0.287045              -0.217641   \n",
       "user_id                               0.244540               0.243528   \n",
       "postingFrequency                      0.207535               0.094307   \n",
       "postingInterval                      -0.129792              -0.050716   \n",
       "generalMoreFreq                      -0.105823              -0.056529   \n",
       "generalWordCount                     -0.043440              -0.015375   \n",
       "healthPostingFrequency                1.000000               0.111994   \n",
       "healthPostingInterval                 0.111994               1.000000   \n",
       "healthMoreFreq                        0.450643               0.141597   \n",
       "healthWordCount                       0.281709               0.439995   \n",
       "mentionMethods                        0.305542               0.237163   \n",
       "raw_label                            -0.273528              -0.281528   \n",
       "\n",
       "                        healthMoreFreq  healthWordCount  mentionMethods  \\\n",
       "Unnamed: 0                   -0.278780        -0.315687       -0.431874   \n",
       "user_id                       0.256826         0.334215        0.437470   \n",
       "postingFrequency              0.119960         0.088490        0.052350   \n",
       "postingInterval              -0.070599        -0.124361       -0.036222   \n",
       "generalMoreFreq              -0.019006        -0.050714       -0.057623   \n",
       "generalWordCount             -0.053404        -0.067816       -0.105905   \n",
       "healthPostingFrequency        0.450643         0.281709        0.305542   \n",
       "healthPostingInterval         0.141597         0.439995        0.237163   \n",
       "healthMoreFreq                1.000000         0.303944        0.266511   \n",
       "healthWordCount               0.303944         1.000000        0.239671   \n",
       "mentionMethods                0.266511         0.239671        1.000000   \n",
       "raw_label                    -0.285577        -0.383654       -0.509683   \n",
       "\n",
       "                        raw_label  \n",
       "Unnamed: 0               0.871057  \n",
       "user_id                 -0.863848  \n",
       "postingFrequency        -0.051934  \n",
       "postingInterval          0.118072  \n",
       "generalMoreFreq          0.031912  \n",
       "generalWordCount         0.241434  \n",
       "healthPostingFrequency  -0.273528  \n",
       "healthPostingInterval   -0.281528  \n",
       "healthMoreFreq          -0.285577  \n",
       "healthWordCount         -0.383654  \n",
       "mentionMethods          -0.509683  \n",
       "raw_label                1.000000  "
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's see correlation between  SW and control\n",
    "#raw label already tells which one is control, so the correlation is high\n",
    "allF['raw_label'] = allF['raw_label'].replace(['a', 'b', 'c', 'd', 'e'], [1, 1, 1, 1, 2]) \n",
    "allF.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we only select the risk class\n",
    "allF = pd.merge(freqFea, labels, on = 'user_id',how = 'right')\n",
    "allF['raw_label'] = allF['raw_label'].replace(['a', 'b', 'c', 'd', 'e'], [1, 2, 3, 4, 5]) \n",
    "selected = allF[allF['raw_label'] < 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>postingFrequency</th>\n",
       "      <th>postingInterval</th>\n",
       "      <th>generalMoreFreq</th>\n",
       "      <th>generalWordCount</th>\n",
       "      <th>healthPostingFrequency</th>\n",
       "      <th>healthPostingInterval</th>\n",
       "      <th>healthMoreFreq</th>\n",
       "      <th>healthWordCount</th>\n",
       "      <th>mentionMethods</th>\n",
       "      <th>raw_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013388</td>\n",
       "      <td>-0.056022</td>\n",
       "      <td>0.048893</td>\n",
       "      <td>-0.037471</td>\n",
       "      <td>-0.008979</td>\n",
       "      <td>-0.143462</td>\n",
       "      <td>0.081731</td>\n",
       "      <td>-0.099477</td>\n",
       "      <td>0.051577</td>\n",
       "      <td>0.038069</td>\n",
       "      <td>0.040782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>-0.013388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038646</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>-0.062239</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>-0.011334</td>\n",
       "      <td>0.019459</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>-0.009531</td>\n",
       "      <td>-0.038211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postingFrequency</th>\n",
       "      <td>-0.056022</td>\n",
       "      <td>0.038646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.380079</td>\n",
       "      <td>-0.271637</td>\n",
       "      <td>0.067116</td>\n",
       "      <td>0.389477</td>\n",
       "      <td>0.123048</td>\n",
       "      <td>0.192301</td>\n",
       "      <td>0.108689</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>-0.007305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postingInterval</th>\n",
       "      <td>0.048893</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>-0.380079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196679</td>\n",
       "      <td>-0.032103</td>\n",
       "      <td>-0.156386</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>-0.055583</td>\n",
       "      <td>-0.120095</td>\n",
       "      <td>0.046750</td>\n",
       "      <td>-0.036449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalMoreFreq</th>\n",
       "      <td>-0.037471</td>\n",
       "      <td>-0.062239</td>\n",
       "      <td>-0.271637</td>\n",
       "      <td>0.196679</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.073470</td>\n",
       "      <td>-0.134849</td>\n",
       "      <td>-0.053965</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>-0.056976</td>\n",
       "      <td>-0.065821</td>\n",
       "      <td>0.001327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalWordCount</th>\n",
       "      <td>-0.008979</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>0.067116</td>\n",
       "      <td>-0.032103</td>\n",
       "      <td>-0.073470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.074579</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>-0.057884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthPostingFrequency</th>\n",
       "      <td>-0.143462</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>0.389477</td>\n",
       "      <td>-0.156386</td>\n",
       "      <td>-0.134849</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.406249</td>\n",
       "      <td>0.188263</td>\n",
       "      <td>0.201855</td>\n",
       "      <td>0.176687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthPostingInterval</th>\n",
       "      <td>0.081731</td>\n",
       "      <td>-0.011334</td>\n",
       "      <td>0.123048</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>-0.053965</td>\n",
       "      <td>0.074579</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058725</td>\n",
       "      <td>0.359925</td>\n",
       "      <td>0.129084</td>\n",
       "      <td>-0.054990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthMoreFreq</th>\n",
       "      <td>-0.099477</td>\n",
       "      <td>0.019459</td>\n",
       "      <td>0.192301</td>\n",
       "      <td>-0.055583</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.406249</td>\n",
       "      <td>0.058725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210601</td>\n",
       "      <td>0.151030</td>\n",
       "      <td>0.121501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthWordCount</th>\n",
       "      <td>0.051577</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.108689</td>\n",
       "      <td>-0.120095</td>\n",
       "      <td>-0.056976</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.188263</td>\n",
       "      <td>0.359925</td>\n",
       "      <td>0.210601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059691</td>\n",
       "      <td>0.006132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentionMethods</th>\n",
       "      <td>0.038069</td>\n",
       "      <td>-0.009531</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>0.046750</td>\n",
       "      <td>-0.065821</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>0.201855</td>\n",
       "      <td>0.129084</td>\n",
       "      <td>0.151030</td>\n",
       "      <td>0.059691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.256812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_label</th>\n",
       "      <td>0.040782</td>\n",
       "      <td>-0.038211</td>\n",
       "      <td>-0.007305</td>\n",
       "      <td>-0.036449</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>-0.057884</td>\n",
       "      <td>0.176687</td>\n",
       "      <td>-0.054990</td>\n",
       "      <td>0.121501</td>\n",
       "      <td>0.006132</td>\n",
       "      <td>0.256812</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Unnamed: 0   user_id  postingFrequency  \\\n",
       "Unnamed: 0                1.000000 -0.013388         -0.056022   \n",
       "user_id                  -0.013388  1.000000          0.038646   \n",
       "postingFrequency         -0.056022  0.038646          1.000000   \n",
       "postingInterval           0.048893  0.002519         -0.380079   \n",
       "generalMoreFreq          -0.037471 -0.062239         -0.271637   \n",
       "generalWordCount         -0.008979  0.048660          0.067116   \n",
       "healthPostingFrequency   -0.143462  0.026460          0.389477   \n",
       "healthPostingInterval     0.081731 -0.011334          0.123048   \n",
       "healthMoreFreq           -0.099477  0.019459          0.192301   \n",
       "healthWordCount           0.051577  0.013395          0.108689   \n",
       "mentionMethods            0.038069 -0.009531          0.061198   \n",
       "raw_label                 0.040782 -0.038211         -0.007305   \n",
       "\n",
       "                        postingInterval  generalMoreFreq  generalWordCount  \\\n",
       "Unnamed: 0                     0.048893        -0.037471         -0.008979   \n",
       "user_id                        0.002519        -0.062239          0.048660   \n",
       "postingFrequency              -0.380079        -0.271637          0.067116   \n",
       "postingInterval                1.000000         0.196679         -0.032103   \n",
       "generalMoreFreq                0.196679         1.000000         -0.073470   \n",
       "generalWordCount              -0.032103        -0.073470          1.000000   \n",
       "healthPostingFrequency        -0.156386        -0.134849          0.028411   \n",
       "healthPostingInterval          0.014346        -0.053965          0.074579   \n",
       "healthMoreFreq                -0.055583         0.014884          0.012679   \n",
       "healthWordCount               -0.120095        -0.056976          0.023354   \n",
       "mentionMethods                 0.046750        -0.065821          0.030195   \n",
       "raw_label                     -0.036449         0.001327         -0.057884   \n",
       "\n",
       "                        healthPostingFrequency  healthPostingInterval  \\\n",
       "Unnamed: 0                           -0.143462               0.081731   \n",
       "user_id                               0.026460              -0.011334   \n",
       "postingFrequency                      0.389477               0.123048   \n",
       "postingInterval                      -0.156386               0.014346   \n",
       "generalMoreFreq                      -0.134849              -0.053965   \n",
       "generalWordCount                      0.028411               0.074579   \n",
       "healthPostingFrequency                1.000000               0.012622   \n",
       "healthPostingInterval                 0.012622               1.000000   \n",
       "healthMoreFreq                        0.406249               0.058725   \n",
       "healthWordCount                       0.188263               0.359925   \n",
       "mentionMethods                        0.201855               0.129084   \n",
       "raw_label                             0.176687              -0.054990   \n",
       "\n",
       "                        healthMoreFreq  healthWordCount  mentionMethods  \\\n",
       "Unnamed: 0                   -0.099477         0.051577        0.038069   \n",
       "user_id                       0.019459         0.013395       -0.009531   \n",
       "postingFrequency              0.192301         0.108689        0.061198   \n",
       "postingInterval              -0.055583        -0.120095        0.046750   \n",
       "generalMoreFreq               0.014884        -0.056976       -0.065821   \n",
       "generalWordCount              0.012679         0.023354        0.030195   \n",
       "healthPostingFrequency        0.406249         0.188263        0.201855   \n",
       "healthPostingInterval         0.058725         0.359925        0.129084   \n",
       "healthMoreFreq                1.000000         0.210601        0.151030   \n",
       "healthWordCount               0.210601         1.000000        0.059691   \n",
       "mentionMethods                0.151030         0.059691        1.000000   \n",
       "raw_label                     0.121501         0.006132        0.256812   \n",
       "\n",
       "                        raw_label  \n",
       "Unnamed: 0               0.040782  \n",
       "user_id                 -0.038211  \n",
       "postingFrequency        -0.007305  \n",
       "postingInterval         -0.036449  \n",
       "generalMoreFreq          0.001327  \n",
       "generalWordCount        -0.057884  \n",
       "healthPostingFrequency   0.176687  \n",
       "healthPostingInterval   -0.054990  \n",
       "healthMoreFreq           0.121501  \n",
       "healthWordCount          0.006132  \n",
       "mentionMethods           0.256812  \n",
       "raw_label                1.000000  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's observe highest risk to all \n",
    "selected['raw_label'] = selected['raw_label'].replace([1, 2, 3, 4], [1, 1, 1, 2]) \n",
    "selected.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>postingFrequency</th>\n",
       "      <th>postingInterval</th>\n",
       "      <th>generalMoreFreq</th>\n",
       "      <th>generalWordCount</th>\n",
       "      <th>healthPostingFrequency</th>\n",
       "      <th>healthPostingInterval</th>\n",
       "      <th>healthMoreFreq</th>\n",
       "      <th>healthWordCount</th>\n",
       "      <th>mentionMethods</th>\n",
       "      <th>raw_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013388</td>\n",
       "      <td>-0.056022</td>\n",
       "      <td>0.048893</td>\n",
       "      <td>-0.037471</td>\n",
       "      <td>-0.008979</td>\n",
       "      <td>-0.143462</td>\n",
       "      <td>0.081731</td>\n",
       "      <td>-0.099477</td>\n",
       "      <td>0.051577</td>\n",
       "      <td>0.038069</td>\n",
       "      <td>0.075589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>-0.013388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038646</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>-0.062239</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>-0.011334</td>\n",
       "      <td>0.019459</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>-0.009531</td>\n",
       "      <td>-0.038189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postingFrequency</th>\n",
       "      <td>-0.056022</td>\n",
       "      <td>0.038646</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.380079</td>\n",
       "      <td>-0.271637</td>\n",
       "      <td>0.067116</td>\n",
       "      <td>0.389477</td>\n",
       "      <td>0.123048</td>\n",
       "      <td>0.192301</td>\n",
       "      <td>0.108689</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>-0.060779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>postingInterval</th>\n",
       "      <td>0.048893</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>-0.380079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.196679</td>\n",
       "      <td>-0.032103</td>\n",
       "      <td>-0.156386</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>-0.055583</td>\n",
       "      <td>-0.120095</td>\n",
       "      <td>0.046750</td>\n",
       "      <td>-0.023466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalMoreFreq</th>\n",
       "      <td>-0.037471</td>\n",
       "      <td>-0.062239</td>\n",
       "      <td>-0.271637</td>\n",
       "      <td>0.196679</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.073470</td>\n",
       "      <td>-0.134849</td>\n",
       "      <td>-0.053965</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>-0.056976</td>\n",
       "      <td>-0.065821</td>\n",
       "      <td>0.075024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>generalWordCount</th>\n",
       "      <td>-0.008979</td>\n",
       "      <td>0.048660</td>\n",
       "      <td>0.067116</td>\n",
       "      <td>-0.032103</td>\n",
       "      <td>-0.073470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>0.074579</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>-0.070732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthPostingFrequency</th>\n",
       "      <td>-0.143462</td>\n",
       "      <td>0.026460</td>\n",
       "      <td>0.389477</td>\n",
       "      <td>-0.156386</td>\n",
       "      <td>-0.134849</td>\n",
       "      <td>0.028411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>0.406249</td>\n",
       "      <td>0.188263</td>\n",
       "      <td>0.201855</td>\n",
       "      <td>0.166956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthPostingInterval</th>\n",
       "      <td>0.081731</td>\n",
       "      <td>-0.011334</td>\n",
       "      <td>0.123048</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>-0.053965</td>\n",
       "      <td>0.074579</td>\n",
       "      <td>0.012622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058725</td>\n",
       "      <td>0.359925</td>\n",
       "      <td>0.129084</td>\n",
       "      <td>-0.011432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthMoreFreq</th>\n",
       "      <td>-0.099477</td>\n",
       "      <td>0.019459</td>\n",
       "      <td>0.192301</td>\n",
       "      <td>-0.055583</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.406249</td>\n",
       "      <td>0.058725</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.210601</td>\n",
       "      <td>0.151030</td>\n",
       "      <td>0.142213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>healthWordCount</th>\n",
       "      <td>0.051577</td>\n",
       "      <td>0.013395</td>\n",
       "      <td>0.108689</td>\n",
       "      <td>-0.120095</td>\n",
       "      <td>-0.056976</td>\n",
       "      <td>0.023354</td>\n",
       "      <td>0.188263</td>\n",
       "      <td>0.359925</td>\n",
       "      <td>0.210601</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059691</td>\n",
       "      <td>0.042622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentionMethods</th>\n",
       "      <td>0.038069</td>\n",
       "      <td>-0.009531</td>\n",
       "      <td>0.061198</td>\n",
       "      <td>0.046750</td>\n",
       "      <td>-0.065821</td>\n",
       "      <td>0.030195</td>\n",
       "      <td>0.201855</td>\n",
       "      <td>0.129084</td>\n",
       "      <td>0.151030</td>\n",
       "      <td>0.059691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.237135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw_label</th>\n",
       "      <td>0.075589</td>\n",
       "      <td>-0.038189</td>\n",
       "      <td>-0.060779</td>\n",
       "      <td>-0.023466</td>\n",
       "      <td>0.075024</td>\n",
       "      <td>-0.070732</td>\n",
       "      <td>0.166956</td>\n",
       "      <td>-0.011432</td>\n",
       "      <td>0.142213</td>\n",
       "      <td>0.042622</td>\n",
       "      <td>0.237135</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Unnamed: 0   user_id  postingFrequency  \\\n",
       "Unnamed: 0                1.000000 -0.013388         -0.056022   \n",
       "user_id                  -0.013388  1.000000          0.038646   \n",
       "postingFrequency         -0.056022  0.038646          1.000000   \n",
       "postingInterval           0.048893  0.002519         -0.380079   \n",
       "generalMoreFreq          -0.037471 -0.062239         -0.271637   \n",
       "generalWordCount         -0.008979  0.048660          0.067116   \n",
       "healthPostingFrequency   -0.143462  0.026460          0.389477   \n",
       "healthPostingInterval     0.081731 -0.011334          0.123048   \n",
       "healthMoreFreq           -0.099477  0.019459          0.192301   \n",
       "healthWordCount           0.051577  0.013395          0.108689   \n",
       "mentionMethods            0.038069 -0.009531          0.061198   \n",
       "raw_label                 0.075589 -0.038189         -0.060779   \n",
       "\n",
       "                        postingInterval  generalMoreFreq  generalWordCount  \\\n",
       "Unnamed: 0                     0.048893        -0.037471         -0.008979   \n",
       "user_id                        0.002519        -0.062239          0.048660   \n",
       "postingFrequency              -0.380079        -0.271637          0.067116   \n",
       "postingInterval                1.000000         0.196679         -0.032103   \n",
       "generalMoreFreq                0.196679         1.000000         -0.073470   \n",
       "generalWordCount              -0.032103        -0.073470          1.000000   \n",
       "healthPostingFrequency        -0.156386        -0.134849          0.028411   \n",
       "healthPostingInterval          0.014346        -0.053965          0.074579   \n",
       "healthMoreFreq                -0.055583         0.014884          0.012679   \n",
       "healthWordCount               -0.120095        -0.056976          0.023354   \n",
       "mentionMethods                 0.046750        -0.065821          0.030195   \n",
       "raw_label                     -0.023466         0.075024         -0.070732   \n",
       "\n",
       "                        healthPostingFrequency  healthPostingInterval  \\\n",
       "Unnamed: 0                           -0.143462               0.081731   \n",
       "user_id                               0.026460              -0.011334   \n",
       "postingFrequency                      0.389477               0.123048   \n",
       "postingInterval                      -0.156386               0.014346   \n",
       "generalMoreFreq                      -0.134849              -0.053965   \n",
       "generalWordCount                      0.028411               0.074579   \n",
       "healthPostingFrequency                1.000000               0.012622   \n",
       "healthPostingInterval                 0.012622               1.000000   \n",
       "healthMoreFreq                        0.406249               0.058725   \n",
       "healthWordCount                       0.188263               0.359925   \n",
       "mentionMethods                        0.201855               0.129084   \n",
       "raw_label                             0.166956              -0.011432   \n",
       "\n",
       "                        healthMoreFreq  healthWordCount  mentionMethods  \\\n",
       "Unnamed: 0                   -0.099477         0.051577        0.038069   \n",
       "user_id                       0.019459         0.013395       -0.009531   \n",
       "postingFrequency              0.192301         0.108689        0.061198   \n",
       "postingInterval              -0.055583        -0.120095        0.046750   \n",
       "generalMoreFreq               0.014884        -0.056976       -0.065821   \n",
       "generalWordCount              0.012679         0.023354        0.030195   \n",
       "healthPostingFrequency        0.406249         0.188263        0.201855   \n",
       "healthPostingInterval         0.058725         0.359925        0.129084   \n",
       "healthMoreFreq                1.000000         0.210601        0.151030   \n",
       "healthWordCount               0.210601         1.000000        0.059691   \n",
       "mentionMethods                0.151030         0.059691        1.000000   \n",
       "raw_label                     0.142213         0.042622        0.237135   \n",
       "\n",
       "                        raw_label  \n",
       "Unnamed: 0               0.075589  \n",
       "user_id                 -0.038189  \n",
       "postingFrequency        -0.060779  \n",
       "postingInterval         -0.023466  \n",
       "generalMoreFreq          0.075024  \n",
       "generalWordCount        -0.070732  \n",
       "healthPostingFrequency   0.166956  \n",
       "healthPostingInterval   -0.011432  \n",
       "healthMoreFreq           0.142213  \n",
       "healthWordCount          0.042622  \n",
       "mentionMethods           0.237135  \n",
       "raw_label                1.000000  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allF = pd.merge(freqFea, labels, on = 'user_id',how = 'right')\n",
    "allF['raw_label'] = allF['raw_label'].replace(['a', 'b', 'c', 'd', 'e'], [1, 2, 3, 4, 5]) \n",
    "selected = allF[allF['raw_label'] < 5]\n",
    "selected.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>raw_label</td>    <th>  R-squared:         </th> <td>   0.763</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.759</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   194.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 06 Mar 2019</td> <th>  Prob (F-statistic):</th> <td>7.09e-164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:28:46</td>     <th>  Log-Likelihood:    </th> <td> -1024.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   554</td>      <th>  AIC:               </th> <td>   2066.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   545</td>      <th>  BIC:               </th> <td>   2105.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>postingFrequency</th>       <td>    0.0035</td> <td>    0.001</td> <td>    5.265</td> <td> 0.000</td> <td>    0.002</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>postingInterval</th>        <td>    0.0253</td> <td>    0.003</td> <td>    8.173</td> <td> 0.000</td> <td>    0.019</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>generalMoreFreq</th>        <td>    1.3024</td> <td>    0.122</td> <td>   10.717</td> <td> 0.000</td> <td>    1.064</td> <td>    1.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>generalWordCount</th>       <td>    0.0024</td> <td>    0.001</td> <td>    2.291</td> <td> 0.022</td> <td>    0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>healthPostingFrequency</th> <td>    0.0160</td> <td>    0.006</td> <td>    2.488</td> <td> 0.013</td> <td>    0.003</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>healthPostingInterval</th>  <td> 9.769e-06</td> <td>    0.001</td> <td>    0.015</td> <td> 0.988</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>healthMoreFreq</th>         <td>    0.1853</td> <td>    0.190</td> <td>    0.974</td> <td> 0.331</td> <td>   -0.189</td> <td>    0.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>healthWordCount</th>        <td>    0.0013</td> <td>    0.000</td> <td>    4.444</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mentionMethods</th>         <td>    1.0928</td> <td>    0.133</td> <td>    8.190</td> <td> 0.000</td> <td>    0.831</td> <td>    1.355</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10.575</td> <th>  Durbin-Watson:     </th> <td>   1.575</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.005</td> <th>  Jarque-Bera (JB):  </th> <td>  10.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.327</td> <th>  Prob(JB):          </th> <td> 0.00444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.793</td> <th>  Cond. No.          </th> <td>    918.</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              raw_label   R-squared:                       0.763\n",
       "Model:                            OLS   Adj. R-squared:                  0.759\n",
       "Method:                 Least Squares   F-statistic:                     194.6\n",
       "Date:                Wed, 06 Mar 2019   Prob (F-statistic):          7.09e-164\n",
       "Time:                        15:28:46   Log-Likelihood:                -1024.2\n",
       "No. Observations:                 554   AIC:                             2066.\n",
       "Df Residuals:                     545   BIC:                             2105.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "postingFrequency           0.0035      0.001      5.265      0.000       0.002       0.005\n",
       "postingInterval            0.0253      0.003      8.173      0.000       0.019       0.031\n",
       "generalMoreFreq            1.3024      0.122     10.717      0.000       1.064       1.541\n",
       "generalWordCount           0.0024      0.001      2.291      0.022       0.000       0.004\n",
       "healthPostingFrequency     0.0160      0.006      2.488      0.013       0.003       0.029\n",
       "healthPostingInterval   9.769e-06      0.001      0.015      0.988      -0.001       0.001\n",
       "healthMoreFreq             0.1853      0.190      0.974      0.331      -0.189       0.559\n",
       "healthWordCount            0.0013      0.000      4.444      0.000       0.001       0.002\n",
       "mentionMethods             1.0928      0.133      8.190      0.000       0.831       1.355\n",
       "==============================================================================\n",
       "Omnibus:                       10.575   Durbin-Watson:                   1.575\n",
       "Prob(Omnibus):                  0.005   Jarque-Bera (JB):               10.834\n",
       "Skew:                          -0.327   Prob(JB):                      0.00444\n",
       "Kurtosis:                       2.793   Cond. No.                         918.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's do regression\n",
    "import statsmodels.api as sm\n",
    "X = selected.iloc[:,2:11]\n",
    "y = selected.raw_label\n",
    "# Fit and make the predictions by the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try predict highest risk only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.6356589147286822\n",
      "{'sgdclassifier__alpha': 0.001, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'hinge', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.71      0.66        84\n",
      "           2       0.65      0.54      0.59        83\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       167\n",
      "   macro avg       0.63      0.63      0.63       167\n",
      "weighted avg       0.63      0.63      0.63       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score,\\\n",
    "recall_score, confusion_matrix, classification_report, accuracy_score \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sys import argv\n",
    "import gc\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "\n",
    "selected = allF[allF['raw_label'] < 5]\n",
    "selected['raw_label'] = selected['raw_label'].replace([1, 2, 3, 4], [1, 1, 1, 2]) \n",
    "X = selected.iloc[:,2:11]\n",
    "y = selected.raw_label\n",
    "\n",
    "def SGDclassifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=30)\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(),SGDClassifier(max_iter= 1000))\n",
    "\n",
    "    parameters = [{'sgdclassifier__alpha': [0.01, 0.05, 0.001, 0.005], 'sgdclassifier__class_weight':['balanced'],\n",
    "                  'sgdclassifier__loss': ['hinge','log','modified_huber','squared_hinge', 'perceptron'], \n",
    "                   'sgdclassifier__penalty':['none','l1','l2']}]\n",
    "\n",
    "    grid_search_item = GridSearchCV(clf,\n",
    "                              param_grid = parameters,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = 5,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "    grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "    print('Best scores and best parameters')\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.6459948320413437\n",
      "{'sgdclassifier__alpha': 0.001, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'modified_huber', 'sgdclassifier__penalty': 'none'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.73      0.66        84\n",
      "           2       0.65      0.51      0.57        83\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       167\n",
      "   macro avg       0.62      0.62      0.61       167\n",
      "weighted avg       0.62      0.62      0.61       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "selected = allF[allF['raw_label'] < 5]\n",
    "selected['raw_label'] = selected['raw_label'].replace([1, 2, 3, 4], [1, 1, 1, 2]) \n",
    "X = selected.iloc[:,2:11]\n",
    "y = selected.raw_label\n",
    "\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    258\n",
       "1    128\n",
       "3    117\n",
       "2     51\n",
       "Name: raw_label, dtype: int64"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see number of cases in each group\n",
    "selected = allF[allF['raw_label'] < 5]\n",
    "#selected['raw_label'] = selected['raw_label'].replace([1, 2, 3, 4], [1, 1, 2, 2]) \n",
    "selected['raw_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17897, 6)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's get all the suicide watch posts\n",
    "allData = pd.read_csv(path + '/data/clpsych19_training_data/shared_task_posts.csv')\n",
    "#sample.to_csv('/home/lucia/phd_work/shareTask/data/clpsych19_training_data/sample.csv')\n",
    "\n",
    "SW = allData.loc[allData['subreddit'] == 'SuicideWatch']\n",
    "SW.shape\n",
    "#SW.to_csv('/home/lucia/phd_work/shareTask/data/clpsych19_training_data/SuicideWatch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/home/lucia/phd_work/shareTask/data/clpsych19_training_data/crowd_train.csv')\n",
    "allLabels = pd.merge(SW, labels, on ='user_id', how ='right')\n",
    "allLabels.shape\n",
    "allLabels.to_csv('/home/lucia/phd_work/shareTask/data/clpsych19_training_data/sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check if motivation keywords mentioned in the text\n",
    "\n",
    "def findText(text, wordList):\n",
    "    for item in wordList:\n",
    "        if type(text) is str:\n",
    "            if item in text:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def subsetDictPosts(file, dictionary, newBody):\n",
    "    file[newBody] = file.apply(lambda row: 1 if findText(row[\"post_body\"], dictionary) else 0, axis=1)\n",
    "    return file\n",
    " \n",
    "def CheckKeyWords(file, dictionary, newBody):    \n",
    "    \n",
    "    burden = subsetDictPosts(file, dictionary, newBody)\n",
    "    burden = burden[['user_id',newBody]]\n",
    "    burden = burden[burden[newBody] == 1]\n",
    "    burden = burden.drop_duplicates(subset=None, keep='first', inplace=False)\n",
    "    return burden\n",
    "\n",
    "allLabels = pd.read_csv(path + 'suicideDetection/sample.csv')\n",
    "burden = CheckKeyWords(allLabels, ['burden'], 'Psy_burden')\n",
    "lonely = CheckKeyWords(allLabels, ['lonely'], 'Psy_lonely')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motivation = pd.merge(burden, lonely, on = 'user_id', how = 'outer')\n",
    "motivation = motivation.fillna(0)\n",
    "motivation\n",
    "#merge motivation feature with Frequency features\n",
    "selected = allF[allF['raw_label'] < 5]\n",
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.6408268733850129\n",
      "{'sgdclassifier__alpha': 0.001, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'squared_hinge', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.70      0.64        84\n",
      "           2       0.63      0.51      0.56        83\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       167\n",
      "   macro avg       0.61      0.60      0.60       167\n",
      "weighted avg       0.61      0.60      0.60       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#binary\n",
    "allFea['raw_label'] = allFea['raw_label'].replace([1, 2, 3, 4], [1, 1, 1, 2]) \n",
    "X = allFea.iloc[:,2:11]\n",
    "y = allFea.raw_label\n",
    "\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.45219638242894056\n",
      "{'sgdclassifier__alpha': 0.001, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'hinge', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.29      0.06      0.09        36\n",
      "           2       0.09      0.40      0.14        15\n",
      "           3       0.26      0.15      0.19        33\n",
      "           4       0.65      0.55      0.60        83\n",
      "\n",
      "   micro avg       0.35      0.35      0.35       167\n",
      "   macro avg       0.32      0.29      0.26       167\n",
      "weighted avg       0.44      0.35      0.37       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#multiclass\n",
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "allFea['raw_label'] = allFea['raw_label'].replace([1, 2, 3, 4], [1, 2, 3, 4]) \n",
    "X = allFea.iloc[:,2:11]\n",
    "y = allFea.raw_label\n",
    "\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.6124031007751938\n",
      "{'sgdclassifier__alpha': 0.001, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'log', 'sgdclassifier__penalty': 'l2'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.67      0.47        51\n",
      "           2       0.77      0.48      0.59       116\n",
      "\n",
      "   micro avg       0.54      0.54      0.54       167\n",
      "   macro avg       0.56      0.57      0.53       167\n",
      "weighted avg       0.64      0.54      0.55       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#multiclass\n",
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "allFea['raw_label'] = allFea['raw_label'].replace([1, 2, 3, 4], [1, 1, 2, 2]) \n",
    "X = allFea.iloc[:,2:11]\n",
    "y = allFea.raw_label\n",
    "\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to see how many suicideWatch post people have to decide the frequency window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "add LIWC features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.7906976744186046\n",
      "{'sgdclassifier__alpha': 0.05, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'hinge', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.71      0.74        51\n",
      "           2       0.88      0.91      0.89       116\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       167\n",
      "   macro avg       0.83      0.81      0.82       167\n",
      "weighted avg       0.85      0.85      0.85       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwcUser= liwc.groupby('user_id').mean().reset_index()\n",
    "allFea = pd.merge(allFea, liwcUser, on = 'user_id', how = 'left')\n",
    "allFea['raw_label'] = allFea['raw_label'].replace([1, 2, 3, 4], [1, 1, 2, 2]) \n",
    "X =  allFea.drop(['raw_label'], axis=1)\n",
    "y = allFea.raw_label\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.6459948320413437\n",
      "{'sgdclassifier__alpha': 0.05, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'log', 'sgdclassifier__penalty': 'l2'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.65      0.68        84\n",
      "           2       0.67      0.72      0.70        83\n",
      "\n",
      "   micro avg       0.69      0.69      0.69       167\n",
      "   macro avg       0.69      0.69      0.69       167\n",
      "weighted avg       0.69      0.69      0.69       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwcUser= liwc.groupby('user_id').mean().reset_index()\n",
    "allFea = pd.merge(allFea, liwcUser, on = 'user_id', how = 'left')\n",
    "allFea['raw_label'] = allFea['raw_label'].replace([1, 2, 3, 4], [1, 1, 1, 2]) \n",
    "X =  allFea.drop(['raw_label'], axis=1)\n",
    "y = allFea.raw_label\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the no risk group mainly talk about sb's else's suicidal risk, therefore, just knowning the first person and third person frequency can identify this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.5452196382428941\n",
      "{'sgdclassifier__alpha': 0.05, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'log', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.78      0.68        36\n",
      "           2       0.15      0.13      0.14        15\n",
      "           3       1.00      0.03      0.06        33\n",
      "           4       0.65      0.84      0.74        83\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       167\n",
      "   macro avg       0.60      0.45      0.41       167\n",
      "weighted avg       0.67      0.60      0.54       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwcUser= liwc.groupby('user_id').mean().reset_index()\n",
    "allFea = pd.merge(allFea, liwcUser, on = 'user_id', how = 'left')\n",
    "#allFea['raw_label'] = allFea['raw_label'].replace([1, 2, 3, 4], [1, 1, 1, 2]) \n",
    "X =  allFea.drop(['raw_label'], axis=1)\n",
    "y = allFea.raw_label\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we'll load the semantic tag features, we get a dictionary with tag counts, the tags we need to observe in here include nouns(NN), plural nouns (NNS), comparative words (JJR), modal (MD), proper nound (NNP), plural proper (NNPS), \n",
    "predeterminer (PDT), possessive ending(POS), personal pronoun (PRP), possessive pronoun(PRP$), verbs (VB) (VBD) (VBG) (VBN) (VBZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.7881136950904393\n",
      "{'sgdclassifier__alpha': 0.05, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'log', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.60      0.71      0.65        51\n",
      "           2       0.86      0.79      0.83       116\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       167\n",
      "   macro avg       0.73      0.75      0.74       167\n",
      "weighted avg       0.78      0.77      0.77       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwcUser= liwc.groupby('user_id').mean().reset_index()\n",
    "allFea = pd.merge(allFea, liwcUser, on = 'user_id', how = 'left')\n",
    "tags = pd.read_csv(path + 'suicideDetection/features/TagFea.csv')\n",
    "allFea2 = pd.merge(allFea, tags, on = 'user_id', how = 'left')\n",
    "allFea2['raw_label'] = allFea2['raw_label'].replace([1, 2, 3, 4], [1, 1, 2, 2]) \n",
    "X =  allFea2.drop(['raw_label'], axis=1)\n",
    "y = allFea2.raw_label\n",
    "SGDclassifier(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.7906976744186046\n",
      "{'sgdclassifier__alpha': 0.05, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'log', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.73      0.67        51\n",
      "           2       0.87      0.80      0.83       116\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       167\n",
      "   macro avg       0.74      0.76      0.75       167\n",
      "weighted avg       0.79      0.78      0.78       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "allFea2 = pd.merge(allFea, tags, on = 'user_id', how = 'left')\n",
    "allFea2['raw_label'] = allFea2['raw_label'].replace([1, 2, 3, 4], [1, 1, 2, 2]) \n",
    "X =  allFea2.drop(['raw_label'], axis=1)\n",
    "y = allFea2.raw_label\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.5581395348837209\n",
      "{'sgdclassifier__alpha': 0.05, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'log', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.81      0.70        36\n",
      "           2       0.00      0.00      0.00        15\n",
      "           3       0.50      0.06      0.11        33\n",
      "           4       0.63      0.86      0.73        83\n",
      "\n",
      "   micro avg       0.61      0.61      0.61       167\n",
      "   macro avg       0.44      0.43      0.38       167\n",
      "weighted avg       0.55      0.61      0.53       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "allFea2 = pd.merge(allFea, tags, on = 'user_id', how = 'left')\n",
    "#allFea2['raw_label'] = allFea2['raw_label'].replace([1, 2, 3, 4], [1, 1, 1, 2]) \n",
    "X =  allFea2.drop(['raw_label'], axis=1)\n",
    "y = allFea2.raw_label\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's use the same features to predict the first two classes only \n",
    "still weak at classs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.784\n",
      "{'sgdclassifier__alpha': 0.01, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'hinge', 'sgdclassifier__penalty': 'l2'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.89      0.84        37\n",
      "           2       0.67      0.47      0.55        17\n",
      "\n",
      "   micro avg       0.76      0.76      0.76        54\n",
      "   macro avg       0.73      0.68      0.69        54\n",
      "weighted avg       0.75      0.76      0.75        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "selected = allF[allF['raw_label'] < 3] #here we select the first two classes\n",
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwcUser= liwc.groupby('user_id').mean().reset_index()\n",
    "allFea = pd.merge(allFea, liwcUser, on = 'user_id', how = 'left')\n",
    "tags = pd.read_csv(path + 'suicideDetection/features/TagFea.csv')\n",
    "allFea2 = pd.merge(allFea, tags, on = 'user_id', how = 'left')\n",
    "X =  allFea2.drop(['raw_label'], axis=1)\n",
    "y = allFea2.raw_label\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.6450381679389313\n",
      "{'sgdclassifier__alpha': 0.001, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'modified_huber', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.50      0.47      0.49        38\n",
      "           4       0.74      0.76      0.75        75\n",
      "\n",
      "   micro avg       0.66      0.66      0.66       113\n",
      "   macro avg       0.62      0.62      0.62       113\n",
      "weighted avg       0.66      0.66      0.66       113\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "selected = allF[allF['raw_label'] > 2]\n",
    "selected = selected[selected['raw_label'] < 5] #here we select the later two classes\n",
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwcUser= liwc.groupby('user_id').mean().reset_index()\n",
    "allFea = pd.merge(allFea, liwcUser, on = 'user_id', how = 'left')\n",
    "tags = pd.read_csv(path + 'suicideDetection/features/TagFea.csv')\n",
    "allFea2 = pd.merge(allFea, tags, on = 'user_id', how = 'left')\n",
    "X =  allFea2.drop(['raw_label'], axis=1)\n",
    "y = allFea2.raw_label\n",
    "SGDclassifier(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how about using  stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwcUser= liwc.groupby('user_id').mean().reset_index()\n",
    "allFea = pd.merge(allFea, liwcUser, on = 'user_id', how = 'left')\n",
    "tags = pd.read_csv(path + 'suicideDetection/features/TagFea.csv')\n",
    "#allFea2 = pd.merge(allFea, tags, on = 'user_id', how = 'left')\n",
    "allFea2['raw_label'] = allFea2['raw_label'].replace([1, 2, 3, 4], [1, 1, 2, 2]) \n",
    "X =  allFea2.drop(['raw_label'], axis=1)\n",
    "y = allFea2.raw_label\n",
    "SGDclassifier(X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vecstack import stacking\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwcUser= liwc.groupby('user_id').mean().reset_index()\n",
    "allFea = pd.merge(allFea, liwcUser, on = 'user_id', how = 'left')\n",
    "tags = pd.read_csv(path + 'suicideDetection/features/TagFea.csv')\n",
    "allFea2 = pd.merge(allFea, tags, on = 'user_id', how = 'left')\n",
    "X =  allFea2.drop(['raw_label'], axis=1)\n",
    "y = allFea2.raw_label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from vecstack import StackingTransformer\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [4]\n",
      "metric:       [accuracy_score]\n",
      "variant:      [A]\n",
      "n_estimators: [3]\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    fold  0:  [0.29113924]\n",
      "    fold  1:  [0.19230769]\n",
      "    fold  2:  [0.44155844]\n",
      "    fold  3:  [0.25974026]\n",
      "    fold  4:  [0.34210526]\n",
      "    ----\n",
      "    MEAN:     [0.30537018] + [0.08362349]\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    fold  0:  [0.62025316]\n",
      "    fold  1:  [0.58974359]\n",
      "    fold  2:  [0.57142857]\n",
      "    fold  3:  [0.58441558]\n",
      "    fold  4:  [0.57894737]\n",
      "    ----\n",
      "    MEAN:     [0.58895766] + [0.01678173]\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    fold  0:  [0.58227848]\n",
      "    fold  1:  [0.51282051]\n",
      "    fold  2:  [0.61038961]\n",
      "    fold  3:  [0.62337662]\n",
      "    fold  4:  [0.60526316]\n",
      "    ----\n",
      "    MEAN:     [0.58682568] + [0.03931568]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# As usual in machine learning task we have X_train, y_train, and X_test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "# Initialize 1st level estimators\n",
    "estimators = [\n",
    "#     ('et', ExtraTreesRegressor(random_state=0, n_jobs=-1, \n",
    "#                                n_estimators=100, max_depth=3)),\n",
    "    ('sgd', SGDClassifier(max_iter=1000, tol=1e-3, alpha=0.05, class_weight = 'balanced', loss = 'log', penalty = 'l1')),\n",
    "        \n",
    "    ('rf', RandomForestClassifier(random_state=0, n_jobs=-1, \n",
    "                                  class_weight = 'balanced', max_depth = 5, \n",
    "                                max_features = 'sqrt', max_leaf_nodes= 100, n_estimators = 200)),\n",
    "        \n",
    "    ('xgb', xgb.XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                         colsample_bytree= 1.0, max_depth=3, min_child_weight= 10, gamma= 1.5, subsample= 1.0))\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize StackingTransformer\n",
    "\n",
    "stack = StackingTransformer(estimators=estimators,   # base estimators\n",
    "                            regression= False,            # regression task (if you need \n",
    "                                                        #     classification - set to False)\n",
    "                            variant='A',                # oof for train set, predict test \n",
    "                                                        #     set in each fold and find mean\n",
    "                            metric=accuracy_score, # metric: callable\n",
    "                            #metric=log_loss, \n",
    "                            #needs_proba: boolean,\n",
    "                            stratified = 'boolean',\n",
    "                            n_folds=5,                  # number of folds\n",
    "                            shuffle=True,               # shuffle the data\n",
    "                            random_state=0,             # ensure reproducibility\n",
    "                            verbose=2)                  # print all info\n",
    "\n",
    "# Fit\n",
    "stack = stack.fit(X_train, y_train)\n",
    "\n",
    "# Get your stacked features\n",
    "S_train = stack.transform(X_train)\n",
    "S_test = stack.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:   15.1s\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=5)]: Done 1003 tasks      | elapsed:   36.5s\n",
      "[Parallel(n_jobs=5)]: Done 1448 tasks      | elapsed:   56.2s\n",
      "[Parallel(n_jobs=5)]: Done 1975 tasks      | elapsed:  1.5min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.6252821670428894\n",
      "{'colsample_bytree': 0.6, 'gamma': 0.5, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.6}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70        27\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.60      0.13      0.21        23\n",
      "           4       0.61      0.87      0.72        55\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       111\n",
      "   macro avg       0.48      0.43      0.41       111\n",
      "weighted avg       0.60      0.63      0.57       111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done 2025 out of 2025 | elapsed:  1.5min finished\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#now let's get the best para for the second layer\n",
    "def xgB(x_train, y_train, test):\n",
    "# clf = make_pipeline(StandardScaler(),XGBClassifier())\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "    parameters = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "\n",
    "    clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=5, \n",
    "                   scoring='accuracy',\n",
    "                   verbose=2, refit=True)\n",
    "\n",
    "    grid_search =clf.fit(x_train, y_train)\n",
    "\n",
    "    print('Best scores and best parameters')\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    y_true, y_pred = y_test, grid_search.predict(test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "xgB(S_train, y_train, S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [4]\n",
      "metric:       [accuracy_score]\n",
      "variant:      [A]\n",
      "n_estimators: [3]\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    fold  0:  [0.54430380]\n",
      "    fold  1:  [0.57692308]\n",
      "    fold  2:  [0.54545455]\n",
      "    fold  3:  [0.59740260]\n",
      "    fold  4:  [0.57894737]\n",
      "    ----\n",
      "    MEAN:     [0.56860628] + [0.02064921]\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    fold  0:  [0.62025316]\n",
      "    fold  1:  [0.58974359]\n",
      "    fold  2:  [0.57142857]\n",
      "    fold  3:  [0.58441558]\n",
      "    fold  4:  [0.57894737]\n",
      "    ----\n",
      "    MEAN:     [0.58895766] + [0.01678173]\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    fold  0:  [0.63291139]\n",
      "    fold  1:  [0.58974359]\n",
      "    fold  2:  [0.55844156]\n",
      "    fold  3:  [0.62337662]\n",
      "    fold  4:  [0.60526316]\n",
      "    ----\n",
      "    MEAN:     [0.60194726] + [0.02634641]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming...\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.62      0.68        39\n",
      "           2       0.00      0.00      0.00        11\n",
      "           3       0.43      0.26      0.32        35\n",
      "           4       0.59      0.82      0.68        82\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       167\n",
      "   macro avg       0.44      0.42      0.42       167\n",
      "weighted avg       0.55      0.60      0.56       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[24,  0,  3, 12],\n",
       "       [ 1,  0,  0, 10],\n",
       "       [ 1,  0,  9, 25],\n",
       "       [ 6,  0,  9, 67]])"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "final_estimator = XGBClassifier()\n",
    "\n",
    "\n",
    "steps = [\n",
    "        ('scale', StandardScaler()),\n",
    "         ('stack', stack),\n",
    "         ('final_estimator', final_estimator)]\n",
    "pipe = Pipeline(steps)\n",
    "pipe = pipe.set_params(stack__xgb__colsample_bytree = 0.6, stack__xgb__gamma = 0.5, stack__xgb__max_depth = 3, stack__xgb__min_child_weight = 1, stack__xgb__subsample =0.6)\n",
    "          \n",
    "pipe = pipe.fit(X_train, y_train)\n",
    "# # Predict\n",
    "y_pred_pipe = pipe.predict(X_test)\n",
    "          \n",
    "print(classification_report(y_test, y_pred_pipe))\n",
    "confusion_matrix(y_test, y_pred_pipe)\n",
    "#print('Final prediction score using Pipeline: [%.8f]' % mean_absolute_error(y_test, y_pred_pipe))\n",
    "#print('Final prediction score using Pipeline: [%.8f]' % r2_score(y_test, y_pred_pipe))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about removing class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected = allF[allF['raw_label'] < 5]\n",
    "#selected = selected[selected['raw_label'] > 1]\n",
    "allFea = pd.merge(selected, motivation, on = 'user_id', how = 'left')\n",
    "allFea = allFea.fillna(0)\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwcUser= liwc.groupby('user_id').mean().reset_index()\n",
    "allFea = pd.merge(allFea, liwcUser, on = 'user_id', how = 'left')\n",
    "tags = pd.read_csv(path + 'suicideDetection/features/TagFea.csv')\n",
    "allFea2 = pd.merge(allFea, tags, on = 'user_id', how = 'left')\n",
    "allFea2.to_csv(path + 'suicideDetection/features/allFeatures.csv')\n",
    "X =  allFea2.drop(['raw_label'], axis=1)\n",
    "y = allFea2.raw_label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [3]\n",
      "metric:       [accuracy_score]\n",
      "variant:      [A]\n",
      "n_estimators: [3]\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    fold  0:  [0.24590164]\n",
      "    fold  1:  [0.18333333]\n",
      "    fold  2:  [0.25000000]\n",
      "    fold  3:  [0.33898305]\n",
      "    fold  4:  [0.44827586]\n",
      "    ----\n",
      "    MEAN:     [0.29329878] + [0.09199850]\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    fold  0:  [0.62295082]\n",
      "    fold  1:  [0.68333333]\n",
      "    fold  2:  [0.61666667]\n",
      "    fold  3:  [0.62711864]\n",
      "    fold  4:  [0.62068966]\n",
      "    ----\n",
      "    MEAN:     [0.63415182] + [0.02482221]\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    fold  0:  [0.57377049]\n",
      "    fold  1:  [0.60000000]\n",
      "    fold  2:  [0.60000000]\n",
      "    fold  3:  [0.55932203]\n",
      "    fold  4:  [0.63793103]\n",
      "    ----\n",
      "    MEAN:     [0.59420471] + [0.02688316]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize 1st level estimators\n",
    "estimators = [\n",
    "#     ('et', ExtraTreesRegressor(random_state=0, n_jobs=-1, \n",
    "#                                n_estimators=100, max_depth=3)),\n",
    "    ('sgd', SGDClassifier(max_iter=1000, tol=1e-3, alpha=0.05, class_weight = 'balanced', loss = 'log', penalty = 'l1')),\n",
    "        \n",
    "    ('rf', RandomForestClassifier(random_state=0, n_jobs=-1, \n",
    "                                  class_weight = 'balanced', max_depth = 5, \n",
    "                                max_features = 'sqrt', max_leaf_nodes= 100, n_estimators = 200)),\n",
    "        \n",
    "    ('xgb', xgb.XGBClassifier(random_state=0, n_jobs=-1, learning_rate=0.1, \n",
    "                         colsample_bytree= 1.0, max_depth=3, min_child_weight= 10, gamma= 1.5, subsample= 1.0))\n",
    "]\n",
    "\n",
    "\n",
    "# Initialize StackingTransformer\n",
    "\n",
    "stack = StackingTransformer(estimators=estimators,   # base estimators\n",
    "                            regression= False,            # regression task (if you need \n",
    "                                                        #     classification - set to False)\n",
    "                            variant='A',                # oof for train set, predict test \n",
    "                                                        #     set in each fold and find mean\n",
    "                            metric=accuracy_score, # metric: callable\n",
    "                            #metric=log_loss, \n",
    "                            #needs_proba: boolean,\n",
    "                            stratified = 'boolean',\n",
    "                            n_folds=5,                  # number of folds\n",
    "                            shuffle=True,               # shuffle the data\n",
    "                            random_state=0,             # ensure reproducibility\n",
    "                            verbose=2)                  # print all info\n",
    "\n",
    "# Fit\n",
    "stack = stack.fit(X_train, y_train)\n",
    "\n",
    "# Get your stacked features\n",
    "S_train = stack.transform(X_train)\n",
    "S_test = stack.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [3]\n",
      "metric:       [accuracy_score]\n",
      "variant:      [A]\n",
      "n_estimators: [3]\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    fold  0:  [0.57377049]\n",
      "    fold  1:  [0.58333333]\n",
      "    fold  2:  [0.58333333]\n",
      "    fold  3:  [0.50847458]\n",
      "    fold  4:  [0.56896552]\n",
      "    ----\n",
      "    MEAN:     [0.56357545] + [0.02810639]\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    fold  0:  [0.62295082]\n",
      "    fold  1:  [0.68333333]\n",
      "    fold  2:  [0.61666667]\n",
      "    fold  3:  [0.62711864]\n",
      "    fold  4:  [0.62068966]\n",
      "    ----\n",
      "    MEAN:     [0.63415182] + [0.02482221]\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    fold  0:  [0.59016393]\n",
      "    fold  1:  [0.61666667]\n",
      "    fold  2:  [0.55000000]\n",
      "    fold  3:  [0.57627119]\n",
      "    fold  4:  [0.62068966]\n",
      "    ----\n",
      "    MEAN:     [0.59075829] + [0.02622441]\n",
      "\n",
      "Train set was detected.\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "Transforming...\n",
      "\n",
      "estimator  0: [sgd: SGDClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  1: [rf: RandomForestClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py:331: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "estimator  2: [xgb: XGBClassifier]\n",
      "    model from fold  0: done\n",
      "    model from fold  1: done\n",
      "    model from fold  2: done\n",
      "    model from fold  3: done\n",
      "    model from fold  4: done\n",
      "    ----\n",
      "    DONE\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       1.00      0.04      0.08        46\n",
      "           4       0.56      1.00      0.71        70\n",
      "\n",
      "   micro avg       0.56      0.56      0.56       128\n",
      "   macro avg       0.52      0.35      0.27       128\n",
      "weighted avg       0.66      0.56      0.42       128\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 12],\n",
       "       [ 0,  2, 44],\n",
       "       [ 0,  0, 70]])"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "final_estimator = XGBClassifier()\n",
    "\n",
    "\n",
    "steps = [\n",
    "        ('scale', StandardScaler()),\n",
    "         ('stack', stack),\n",
    "         ('final_estimator', final_estimator)]\n",
    "pipe = Pipeline(steps)\n",
    "pipe = pipe.set_params(stack__xgb__colsample_bytree = 0.6, stack__xgb__gamma = 0.5, stack__xgb__max_depth = 3, stack__xgb__min_child_weight = 1, stack__xgb__subsample =0.6)\n",
    "          \n",
    "pipe = pipe.fit(X_train, y_train)\n",
    "# # Predict\n",
    "y_pred_pipe = pipe.predict(X_test)\n",
    "          \n",
    "print(classification_report(y_test, y_pred_pipe))\n",
    "confusion_matrix(y_test, y_pred_pipe)\n",
    "#print('Final prediction score using Pipeline: [%.8f]' % mean_absolute_error(y_test, y_pred_pipe))\n",
    "#print('Final prediction score using Pipeline: [%.8f]' % r2_score(y_test, y_pred_pipe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.6253229974160207\n",
      "{'randomforestclassifier__class_weight': 'balanced', 'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 'sqrt', 'randomforestclassifier__max_leaf_nodes': 100, 'randomforestclassifier__n_estimators': 200}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.89      0.74        36\n",
      "           2       0.00      0.00      0.00        15\n",
      "           3       0.44      0.21      0.29        33\n",
      "           4       0.66      0.81      0.73        83\n",
      "\n",
      "   micro avg       0.63      0.63      0.63       167\n",
      "   macro avg       0.44      0.48      0.44       167\n",
      "weighted avg       0.55      0.63      0.58       167\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def RFclassifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=30)\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(),RandomForestClassifier())\n",
    "\n",
    "    parameters = [{'randomforestclassifier__max_features':['auto','sqrt','log2'], 'randomforestclassifier__class_weight':['balanced'], \n",
    "           'randomforestclassifier__max_leaf_nodes':[10,50,100], 'randomforestclassifier__max_depth':[2,5,10,20], 'randomforestclassifier__n_estimators' : [50,100,200,300,400]}]\n",
    "\n",
    "\n",
    "    grid_search_item = GridSearchCV(clf,\n",
    "                              param_grid = parameters,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = 5,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "    grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "    print('Best scores and best parameters')\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "RFclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   42.3s\n",
      "[Parallel(n_jobs=5)]: Done 152 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=5)]: Done 355 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=5)]: Done 638 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=5)]: Done 1003 tasks      | elapsed: 70.3min\n",
      "[Parallel(n_jobs=5)]: Done 1448 tasks      | elapsed: 76.5min\n",
      "[Parallel(n_jobs=5)]: Done 1975 tasks      | elapsed: 86.4min\n",
      "[Parallel(n_jobs=5)]: Done 2025 out of 2025 | elapsed: 87.3min finished\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.6408268733850129\n",
      "{'colsample_bytree': 1.0, 'gamma': 1.5, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 1.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.89      0.74        36\n",
      "           2       1.00      0.07      0.12        15\n",
      "           3       0.29      0.15      0.20        33\n",
      "           4       0.62      0.73      0.67        83\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       167\n",
      "   macro avg       0.64      0.46      0.43       167\n",
      "weighted avg       0.59      0.59      0.54       167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def xgboostClassifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=30)\n",
    "\n",
    "   # clf = make_pipeline(StandardScaler(),XGBClassifier())\n",
    "    xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "\n",
    "    parameters = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5]\n",
    "        }\n",
    "\n",
    "\n",
    "    clf = GridSearchCV(xgb_model, parameters, n_jobs=5, \n",
    "                   cv=5, \n",
    "                   scoring='accuracy',\n",
    "                   verbose=2, refit=True)\n",
    "    \n",
    "    grid_search =clf.fit(X_train, y_train)\n",
    "   \n",
    "    print('Best scores and best parameters')\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "xgboostClassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['base_score', 'booster', 'colsample_bylevel', 'colsample_bytree', 'gamma', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'n_estimators', 'n_jobs', 'nthread', 'objective', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'seed', 'silent', 'subsample'])"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def RFclassifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=30)\n",
    "\n",
    "    clf = make_pipeline(StandardScaler(),RandomForestClassifier())\n",
    "\n",
    "    parameters = [{'randomforestclassifier__max_features':['auto','sqrt','log2'], 'randomforestclassifier__class_weight':['balanced'], \n",
    "           'randomforestclassifier__max_leaf_nodes':[10,50,100], 'randomforestclassifier__max_depth':[2,5,10,20], 'randomforestclassifier__n_estimators' : [50,100,200,300,400]}]\n",
    "\n",
    "\n",
    "    grid_search_item = GridSearchCV(clf,\n",
    "                              param_grid = parameters,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = 5,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "    grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "    print('Best scores and best parameters')\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "RFclassifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "let's add count vect as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not / are not / is not / has not / have not\",\n",
    "\"aren't\": \"are not / am not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he had / he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he shall / he will\",\n",
    "\"he'll've\": \"he shall have / he will have\",\n",
    "\"he's\": \"he has / he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how has / how is / how does\",\n",
    "\"I'd\": \"I had / I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I shall / I will\",\n",
    "\"I'll've\": \"I shall have / I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it had / it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it shall / it will\",\n",
    "\"it'll've\": \"it shall have / it will have\",\n",
    "\"it's\": \"it has / it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she had / she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she shall / she will\",\n",
    "\"she'll've\": \"she shall have / she will have\",\n",
    "\"she's\": \"she has / she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as / so is\",\n",
    "\"that'd\": \"that would / that had\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that has / that is\",\n",
    "\"there'd\": \"there had / there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there has / there is\",\n",
    "\"they'd\": \"they had / they would\",\n",
    "\"they'd've\": \"they would have\",\n",
    "\"they'll\": \"they shall / they will\",\n",
    "\"they'll've\": \"they shall have / they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we had / we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what shall / what will\",\n",
    "\"what'll've\": \"what shall have / what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what has / what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when has / when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where has / where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who shall / who will\",\n",
    "\"who'll've\": \"who shall have / who will have\",\n",
    "\"who's\": \"who has / who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why has / why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you had / you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you shall / you will\",\n",
    "\"you'll've\": \"you shall have / you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(sent):\n",
    "\n",
    "    words = str(sent).split()\n",
    "    new_words = []\n",
    "    ps = PorterStemmer()\n",
    "    for w in words:\n",
    "        if w in list(contractions.keys()):\n",
    "            w = contractions[w]\n",
    "        # remove non English word characters\n",
    "        w = re.sub(r'[^\\x00-\\x7F]+',' ', w).lower()\n",
    "        # remove puncutation \n",
    "        w = re.sub(r'[^\\w\\s]','',w)\n",
    "        #remove digits\n",
    "        w = re.sub(r'[0-9]+', '', w)  \n",
    "        w = ps.stem(w)\n",
    "        \n",
    "            \n",
    "        if w not in set(stopwords.words('english')):\n",
    "            new_words.append(w)\n",
    "        \n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small = SW.head(10)\n",
    "SW2 = small.groupby('user_id').post_body.apply(lambda x: x).reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "VecCounts = vectorizer.fit_transform(SW.post_body.astype('U'))\n",
    "print(VecCounts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17897, 35509)\n"
     ]
    }
   ],
   "source": [
    "print(VecCounts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-7c3a16d9b78e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVecCountsDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVecCounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "VecCountsDf = pd.DataFrame(VecCounts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
