{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score,\\\n",
    "recall_score, confusion_matrix, classification_report, accuracy_score \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sys import argv\n",
    "import gc\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(496, 146)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/lucia/phd_work/Clpsy/'\n",
    "features = pd.read_csv(path + 'suicideDetection/features/FreqSentiMotiTopiFea.csv')\n",
    "#merge with liwc data\n",
    "liwc = pd.read_csv(path + 'suicideDetection/features/liwcSW.csv')\n",
    "liwc = liwc.rename(columns = {liwc.columns[2]:'user_id'})\n",
    "liwcUser = liwc.groupby('user_id').mean().reset_index()\n",
    "liwcUser = liwcUser.drop(['Source (A)', 'Source (D)'], axis=1)\n",
    "allfea = pd.merge(features, liwcUser, on = 'user_id', how = 'right')\n",
    "# merge empath\n",
    "empath = pd.read_csv(path + 'suicideDetection/features/empathSW.csv')\n",
    "allfea = pd.merge(allfea, empath, on = 'user_id', how = 'right')\n",
    "#merge tags\n",
    "# tags = pd.read_csv(path + 'suicideDetection/features/TagFeaSW.csv')\n",
    "# allfea = pd.merge(allfea, tags, on = 'user_id', how = 'right')\n",
    "\n",
    "allfea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 143)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lmodeltest = pd.read_csv(path + 'data/languageModel/allPtest.csv')\n",
    "testId = Lmodeltest['user_id']\n",
    "testId = testId.drop_duplicates(keep='first', inplace=False).to_frame()\n",
    "X_train = pd.merge(allfea, testId, on = 'user_id', how='right')\n",
    "y_train = X_train.raw_label \n",
    "X_train = X_train.iloc[:, 3:146]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248, 143)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train = pd.merge(allfea, testId, on = 'user_id', how='outer')\n",
    "X_test = allfea[(~allfea.user_id.isin(testId.user_id))]\n",
    "y_test = X_test.raw_label \n",
    "X_test = X_test.iloc[:, 3:146]\n",
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.41935483870967744\n",
      "{'sgdclassifier__alpha': 0.01, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'perceptron', 'sgdclassifier__penalty': 'none'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.56      0.59        61\n",
      "           2       0.07      0.25      0.11        20\n",
      "           3       0.25      0.16      0.19        51\n",
      "           4       0.58      0.43      0.50       116\n",
      "\n",
      "   micro avg       0.39      0.39      0.39       248\n",
      "   macro avg       0.38      0.35      0.34       248\n",
      "weighted avg       0.48      0.39      0.42       248\n",
      "\n",
      "[[34 14  7  6]\n",
      " [ 4  5  4  7]\n",
      " [ 3 17  8 23]\n",
      " [14 39 13 50]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "X = allfea.iloc[:, 3:146]\n",
    "y = allfea.raw_label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=30)\n",
    "\n",
    "def SGDclassifier(X_train, X_test, y_train, y_test):\n",
    "    smote_enn = SMOTEENN(random_state=42)\n",
    "\n",
    "    clf = make_pipeline(smote_enn, StandardScaler(), SGDClassifier(max_iter= 1000))\n",
    "\n",
    "    parameters = [{'sgdclassifier__alpha': [0.01, 0.05, 0.001, 0.005], 'sgdclassifier__class_weight':['balanced'],\n",
    "                  'sgdclassifier__loss': ['hinge','log','modified_huber','squared_hinge', 'perceptron'], \n",
    "                   'sgdclassifier__penalty':['none','l1','l2']}]\n",
    "\n",
    "    grid_search_item = GridSearchCV(clf,\n",
    "                              param_grid = parameters,\n",
    "                               scoring = 'accuracy',\n",
    "                               cv = 5,\n",
    "                               n_jobs = -1)\n",
    "\n",
    "    grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "    print('Best scores and best parameters')\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "SGDclassifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.49193548387096775\n",
      "{'sgdclassifier__alpha': 0.01, 'sgdclassifier__class_weight': 'balanced', 'sgdclassifier__loss': 'modified_huber', 'sgdclassifier__penalty': 'l1'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.51      0.52        76\n",
      "           2       0.16      0.36      0.23        22\n",
      "           3       0.32      0.24      0.27        55\n",
      "           4       0.45      0.40      0.42        95\n",
      "\n",
      "   micro avg       0.40      0.40      0.40       248\n",
      "   macro avg       0.36      0.38      0.36       248\n",
      "weighted avg       0.42      0.40      0.40       248\n",
      "\n",
      "[[39  8  7 22]\n",
      " [ 4  8  3  7]\n",
      " [12 13 13 17]\n",
      " [19 20 18 38]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "Lmodeltest = pd.read_csv(path + 'data/languageModel/allPtest.csv')\n",
    "testId = Lmodeltest['user_id']\n",
    "testId = testId.drop_duplicates(keep='first', inplace=False).to_frame()\n",
    "X_test = pd.merge(allfea, testId, on = 'user_id', how='right')\n",
    "y_test = X_test.raw_label \n",
    "X_test = X_test.iloc[:, 3:146]\n",
    "X_train = allfea[(~allfea.user_id.isin(testId.user_id))]\n",
    "y_train = X_train.raw_label \n",
    "X_train = X_train.iloc[:, 3:146]\n",
    "SGDclassifier(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed = pd.read_csv(path + 'data/clpsych19_training_data/Stressed.csv')\n",
    "StressedSW = SW.append(stressed, ignore_index=True)\n",
    "StressedSW.to_csv(path + 'data/clpsych19_training_data/StressedSW.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31553\n",
      "15728\n",
      "15825\n",
      "919\n",
      "516\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/lucia/phd_work/Clpsy/'\n",
    "allP = pd.read_csv(path + 'data/clpsych19_training_data/Btrain_NoNoise.csv')\n",
    "SW= pd.read_csv(path + 'data/clpsych19_training_data/Btrain_NoNoise_SW.csv')\n",
    "SW= pd.read_csv(path + 'data/clpsych19_training_data/Btrain_NoNoise_SW.csv')\n",
    "\n",
    "labels = pd.read_csv(path + 'data/clpsych19_training_data/crowd_train.csv')\n",
    "labels = labels.loc[labels['user_id'] > 0]\n",
    "x_train,x_test = train_test_split(labels,test_size=0.5)\n",
    "\n",
    "#get test and train file\n",
    "def mergeFile(file, testSave):\n",
    "    filetrain = pd.merge(file, x_train, on ='user_id', how ='right')\n",
    "    filetest = pd.merge(file, x_test, on ='user_id', how ='right')\n",
    "    filetest.to_csv()\n",
    "    return filetrain\n",
    "\n",
    "testSave1 = path + 'data/languageModel/allPtest.csv'\n",
    "mergeFile(allP, testSave1)\n",
    "\n",
    "testSave2 = path + 'data/languageModel/SWPtest.csv'\n",
    "mergeFile(SW, testSave2)\n",
    "\n",
    "#SWPtrain = pd.merge(SW, x_train, on ='user_id', how ='right')\n",
    "#SWPtest = pd.merge(SW, x_test, on ='user_id', how ='right')\n",
    "#SWPtest.to_csv()\n",
    "\n",
    "print(len(allP))\n",
    "print(len(allPtrain))\n",
    "print(len(allPtest))\n",
    "\n",
    "print(len(SW))\n",
    "print(len(SWPtrain))\n",
    "print(len(SWPtest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClass(file, Class, savePath):\n",
    "    a = file.loc[file['raw_label_x'] == Class]\n",
    "    a = a[['post_body','post_title']]\n",
    "    a.to_csv(savePath)\n",
    "    \n",
    "\n",
    "savePath1 = path + 'data/languageModel/AAll.csv'\n",
    "savePath2 = path + 'data/languageModel/BAll.csv'\n",
    "savePath3 = path + 'data/languageModel/CAll.csv'\n",
    "savePath4 = path + 'data/languageModel/DAll.csv'\n",
    "\n",
    "ClassA = getClass(allPtrain, 'a', savePath1)\n",
    "ClassB = getClass(allPtrain, 'b', savePath2)\n",
    "ClassC = getClass(allPtrain, 'c', savePath3)\n",
    "ClassD = getClass(allPtrain, 'd', savePath4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "savePath1 = path + 'data/languageModel/ASW.csv'\n",
    "savePath2 = path + 'data/languageModel/BSW.csv'\n",
    "savePath3 = path + 'data/languageModel/CSW.csv'\n",
    "savePath4 = path + 'data/languageModel/DSW.csv'\n",
    "\n",
    "ClassA = getClass(SWPtrain, 'a', savePath1)\n",
    "ClassB = getClass(SWPtrain, 'b', savePath2)\n",
    "ClassC = getClass(SWPtrain, 'c', savePath3)\n",
    "ClassD = getClass(SWPtrain, 'd', savePath4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
