{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "import re\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score,\\\n",
    "recall_score, confusion_matrix, classification_report, accuracy_score \n",
    "import nltk\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import pyltr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __GetLIWC(file:str): \n",
    "\tliwc = pd.read_csv(file)\n",
    "\tliwc = liwc.rename(columns = {liwc.columns[2]:'user_id'})\n",
    "\tliwcUser = liwc.groupby('user_id').mean().reset_index()\n",
    "\tliwcUser = liwcUser.drop(['Source (A)', 'Source (D)'], axis=1)\n",
    "\treturn liwcUser\n",
    "\n",
    "def mergeFea(features, liwc, empath): \n",
    "\tfeatures = pd.read_csv(features)\n",
    "\n",
    "\t#merge features\n",
    "\tliwcUser = __GetLIWC(liwc)\n",
    "\tliwcUser2 = liwcUser.iloc[:,1::]\n",
    "\tliwcUser2.columns = [str(col) + '_liwc' for col in liwcUser2.columns]\n",
    "\tliwcUser2['user_id'] = liwcUser.user_id\n",
    "\n",
    "\tempath = pd.read_csv(empath)\n",
    "\tempath2 = empath.iloc[:,1::]\n",
    "\tempath2.columns = [str(col) + '_empath' for col in empath2.columns]\n",
    "\tempath2['user_id'] = empath.user_id\n",
    "\n",
    "\tallfea = pd.merge(features, liwcUser2, on = 'user_id', how = 'right')\n",
    "\tallfea = pd.merge(allfea, empath2, on = 'user_id', how = 'right')\n",
    "\treturn allfea\n",
    "\n",
    "def preprocess2(sent):\n",
    "    #remove punctustion\n",
    "    sent = re.sub(r'[^\\w\\s]','',str(sent))\n",
    "    words = sent.split()\n",
    "    new_words = []\n",
    "    for w in words:      \n",
    "        new_words.append(w.lower())\n",
    "        \n",
    "    return ' '.join(new_words)\n",
    "\n",
    "\n",
    "class ItemSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key].values.reshape(-1,1)\n",
    "    \n",
    "class ItemSelectorText(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/home/lucia/phd_work/shareTask/'\n",
    "#path = '/Users/lucia/phd_work/Clpsy/'\n",
    "X = pd.read_csv(path + '/data/clpsych19_training_data/Btrain_NoNoise_SW.csv')\n",
    "y = pd.read_csv(path + '/data/clpsych19_training_data/crowd_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concatenate text according to user id\n",
    "X1 = X[['user_id','post_body']]\n",
    "conTex = X1.groupby(['user_id'],as_index=False).agg(lambda x : x.sum() if str(x) else ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conTex['post_body'] = conTex['post_body'].apply(lambda x: preprocess2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'user_id', 'raw_label', 'postingFrequency',\n",
       "       'postingInterval', 'generalMoreFreq', 'generalWordCount',\n",
       "       'healthPostingFrequency', 'healthPostingInterval', 'healthMoreFreq',\n",
       "       'healthWordCount', 'mentionMethods', 'SWFrequency', 'SWPostingInterval',\n",
       "       'SWFreq', 'SWWordCount', 'fin_body', 'drug_body', 'mental_body',\n",
       "       'rela_body', 'suicide_body', 'hopeless_body', 'motivations',\n",
       "       'family_senti', 'partner_senti', 'self_senti', 'raw_label.1',\n",
       "       'sentiment', 'mclust'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fea = pd.read_csv(path + '/suicideDetection/features/FreqSentiMotiTopiFea.csv')\n",
    "Fea.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFea = pd.read_csv(path + '/suicideDetection/features/FreqSentiMotiTopiFea.csv')\n",
    "liwc = pd.read_csv(path + '/suicideDetection/features/liwcSW.csv')\n",
    "tags = pd.read_csv(path + '/suicideDetection/features/TagFeaSW.csv')\n",
    "empath = pd.read_csv(path + '/suicideDetection/features/empathSW.csv')\n",
    "readability = pd.read_csv(path + '/suicideDetection/features/readability.csv')\n",
    "embeddings = pd.read_csv(path + '/suicideDetection/features/Embeddings.csv')\n",
    "\n",
    "liwc = liwc.iloc[:,np.r_[2, 8:liwc.shape[1]]]\n",
    "liwc = liwc.rename(columns = {liwc.columns[0]:'user_id'})\n",
    "liwcUser = liwc.groupby('user_id').mean().reset_index()\n",
    "liwcUser.columns = [str(col) + '_liwc' for col in liwcUser.columns]\n",
    "readability = readability.drop(['post_body'], axis = 1)\n",
    "\n",
    "empath.columns = [str(col) + '_empath' for col in empath.columns]\n",
    "tags.columns = [str(col) + '_tag' for col in tags.columns]\n",
    "readability.columns = [str(col) + '_read' for col in readability.columns]\n",
    "allFea = pd.merge(allFea, liwcUser, left_on ='user_id', right_on = 'user_id_liwc', how = 'left')\n",
    "allFea = pd.merge(allFea, empath, left_on ='user_id', right_on = 'user_id_empath', how = 'left')\n",
    "allFea = pd.merge(allFea, tags, left_on ='user_id', right_on = 'user_id_tag', how = 'left')\n",
    "allFea = pd.merge(allFea, readability, left_on ='user_id', right_on = 'user_id_read', how = 'left')\n",
    "allFea = pd.merge(allFea, embeddings, left_on ='user_id', right_on = 'user_id', how = 'left')\n",
    "\n",
    "# # # #liwc\n",
    "# # # allFea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fea = pd.merge(y, conTex, on = 'user_id')\n",
    "allFea2  = pd.merge(conTex, allFea, on = 'user_id')\n",
    "#X = fea['post_body']\n",
    "y = allFea2.raw_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(allFea2, y, test_size=0.30, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347, 185)\n",
      "(347,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'post_body', 'Unnamed: 0_x', 'raw_label', 'postingFrequency',\n",
       "       'postingInterval', 'generalMoreFreq', 'generalWordCount',\n",
       "       'healthPostingFrequency', 'healthPostingInterval',\n",
       "       ...\n",
       "       'Unnamed: 0_read', 'user_id_read', 'readEase_read',\n",
       "       'Flesch-Kincaid_read', 'gunning_fog_read', 'smog_index_read',\n",
       "       'coleman_liau_read', 'linsear_write_read', 'Unnamed: 0_y', 'embedding'],\n",
       "      dtype='object', length=185)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter estimator for estimator Pipeline(memory=None,\n     steps=[('feats', FeatureUnion(n_jobs=None,\n       transformer_list=[('text', Pipeline(memory=None,\n     steps=[('selector', ItemSelectorText(key='post_body')), ('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='c...alty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False))]))]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-52b0f871fd77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mgrid_search_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_item\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;31m# pred = pipe1.predict(X_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# print(classification_report(y_test, pred))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;31m# 3. Step parameters and other initialisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseComposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter estimator for estimator Pipeline(memory=None,\n     steps=[('feats', FeatureUnion(n_jobs=None,\n       transformer_list=[('text', Pipeline(memory=None,\n     steps=[('selector', ItemSelectorText(key='post_body')), ('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='c...alty='l2', random_state=None, solver='warn',\n          tol=0.0001, verbose=0, warm_start=False))]))]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "get_liwc_data = FunctionTransformer(lambda x: x[x.columns[x.columns.to_series().str.contains('liwc')]], validate=False)\n",
    "get_empath_data = FunctionTransformer(lambda x: x[x.columns[x.columns.to_series().str.contains('empath')]], validate=False)\n",
    "get_tags = FunctionTransformer(lambda x: x[x.columns[x.columns.to_series().str.contains('tag')]], validate=False)\n",
    "get_read = FunctionTransformer(lambda x: x[x.columns[x.columns.to_series().str.contains('read')]], validate=False)\n",
    "\n",
    "\n",
    "pipe1 = Pipeline([\n",
    "    \n",
    "    ('feats', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('selector', ItemSelectorText(key='post_body')),\n",
    "            ('cv', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "             ])),\n",
    "#\n",
    "#         ('readability_features', Pipeline([\n",
    "#                 ('selector', get_read)])),\n",
    "        ('liwc_features', get_liwc_data),\n",
    "        ('empath_features', get_empath_data),\n",
    "        ('tag_features', get_tags),\n",
    "        ('selector1', ItemSelector(key='motivations')),\n",
    "#         ('selector2', ItemSelector(key='healthPostingFrequency')),\n",
    "#         ('selector3', ItemSelector(key='healthPostingInterval')),\n",
    "#         ('selector4', ItemSelector(key='healthMoreFreq')),        \n",
    "        ('selector5', ItemSelector(key='healthWordCount')),\n",
    "        ('selector6', ItemSelector(key='mentionMethods')),\n",
    "        \n",
    "#         ('selector7', ItemSelector(key='SWFrequency')),\n",
    "#         ('selector8', ItemSelector(key='SWPostingInterval')),\n",
    "#         ('selector9', ItemSelector(key='SWFreq')),\n",
    "#         ('selector10', ItemSelector(key='suicide_body')),\n",
    "#         ('selector11', ItemSelector(key='hopeless_body')),\n",
    "#         ('selector12', ItemSelector(key='self_senti')),\n",
    "#         ('selector13', ItemSelector(key='mclust')),\n",
    "#         ('selector14', ItemSelector(key='family_senti')),\n",
    "#       ('selector15', ItemSelector(key='embedding')),\n",
    "             ])),\n",
    "    \n",
    "       ('clf', Pipeline([\n",
    "       ('scale', StandardScaler(with_mean=False)),\n",
    "       ('feature_selection', SelectFromModel(RandomForestClassifier(random_state=20))),\n",
    "#        ('svm',  svm.SVC())\n",
    "       ('log', LogisticRegression()),\n",
    "#      ('gbn', GaussianNB()),\n",
    "\n",
    "         ])),\n",
    "])\n",
    "\n",
    "# parameters = [{\n",
    "#             'estimator__clf__svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'estimator__clf__svc__gamma': [0.01, 0.001, 0.0001],\n",
    "#             'estimator__clf__svc__C':[0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.5, 2.0, 10] , 'estimator__clf__svc__class_weight':['balanced']}]\n",
    "# parameters = [{'estimator__clf__feature_selection__estimator__max_depth': [5,10,20], 'estimator__clf__feature_selection__estimator__max_leaf_nodes': [50, 100, 200],\n",
    "#                'estimator__clf__log__C':[1.0, 2.0, 3.0], 'estimator__clf__log__class_weight': ['balanced'], 'estimator__clf__log__multi_class': ['ovr', 'multinomial']}]\n",
    "\n",
    "parameters = [{'estimator__clf__log__C':[1.0, 2.0, 3.0]}]\n",
    "\n",
    "grid_search_item = GridSearchCV(pipe1, parameters, cv = 5, scoring='accuracy')\n",
    "\n",
    "grid_search = grid_search_item.fit(X_train, y_train)\n",
    "# pred = pipe1.predict(X_test)\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv\n",
      "error_score\n",
      "estimator__memory\n",
      "estimator__steps\n",
      "estimator__feats\n",
      "estimator__clf\n",
      "estimator__feats__n_jobs\n",
      "estimator__feats__transformer_list\n",
      "estimator__feats__transformer_weights\n",
      "estimator__feats__text\n",
      "estimator__feats__liwc_features\n",
      "estimator__feats__empath_features\n",
      "estimator__feats__tag_features\n",
      "estimator__feats__selector1\n",
      "estimator__feats__selector5\n",
      "estimator__feats__selector6\n",
      "estimator__feats__text__memory\n",
      "estimator__feats__text__steps\n",
      "estimator__feats__text__selector\n",
      "estimator__feats__text__cv\n",
      "estimator__feats__text__tfidf\n",
      "estimator__feats__text__selector__key\n",
      "estimator__feats__text__cv__analyzer\n",
      "estimator__feats__text__cv__binary\n",
      "estimator__feats__text__cv__decode_error\n",
      "estimator__feats__text__cv__dtype\n",
      "estimator__feats__text__cv__encoding\n",
      "estimator__feats__text__cv__input\n",
      "estimator__feats__text__cv__lowercase\n",
      "estimator__feats__text__cv__max_df\n",
      "estimator__feats__text__cv__max_features\n",
      "estimator__feats__text__cv__min_df\n",
      "estimator__feats__text__cv__ngram_range\n",
      "estimator__feats__text__cv__preprocessor\n",
      "estimator__feats__text__cv__stop_words\n",
      "estimator__feats__text__cv__strip_accents\n",
      "estimator__feats__text__cv__token_pattern\n",
      "estimator__feats__text__cv__tokenizer\n",
      "estimator__feats__text__cv__vocabulary\n",
      "estimator__feats__text__tfidf__norm\n",
      "estimator__feats__text__tfidf__smooth_idf\n",
      "estimator__feats__text__tfidf__sublinear_tf\n",
      "estimator__feats__text__tfidf__use_idf\n",
      "estimator__feats__liwc_features__accept_sparse\n",
      "estimator__feats__liwc_features__check_inverse\n",
      "estimator__feats__liwc_features__func\n",
      "estimator__feats__liwc_features__inv_kw_args\n",
      "estimator__feats__liwc_features__inverse_func\n",
      "estimator__feats__liwc_features__kw_args\n",
      "estimator__feats__liwc_features__pass_y\n",
      "estimator__feats__liwc_features__validate\n",
      "estimator__feats__empath_features__accept_sparse\n",
      "estimator__feats__empath_features__check_inverse\n",
      "estimator__feats__empath_features__func\n",
      "estimator__feats__empath_features__inv_kw_args\n",
      "estimator__feats__empath_features__inverse_func\n",
      "estimator__feats__empath_features__kw_args\n",
      "estimator__feats__empath_features__pass_y\n",
      "estimator__feats__empath_features__validate\n",
      "estimator__feats__tag_features__accept_sparse\n",
      "estimator__feats__tag_features__check_inverse\n",
      "estimator__feats__tag_features__func\n",
      "estimator__feats__tag_features__inv_kw_args\n",
      "estimator__feats__tag_features__inverse_func\n",
      "estimator__feats__tag_features__kw_args\n",
      "estimator__feats__tag_features__pass_y\n",
      "estimator__feats__tag_features__validate\n",
      "estimator__feats__selector1__key\n",
      "estimator__feats__selector5__key\n",
      "estimator__feats__selector6__key\n",
      "estimator__clf__memory\n",
      "estimator__clf__steps\n",
      "estimator__clf__scale\n",
      "estimator__clf__feature_selection\n",
      "estimator__clf__log\n",
      "estimator__clf__scale__copy\n",
      "estimator__clf__scale__with_mean\n",
      "estimator__clf__scale__with_std\n",
      "estimator__clf__feature_selection__estimator__bootstrap\n",
      "estimator__clf__feature_selection__estimator__class_weight\n",
      "estimator__clf__feature_selection__estimator__criterion\n",
      "estimator__clf__feature_selection__estimator__max_depth\n",
      "estimator__clf__feature_selection__estimator__max_features\n",
      "estimator__clf__feature_selection__estimator__max_leaf_nodes\n",
      "estimator__clf__feature_selection__estimator__min_impurity_decrease\n",
      "estimator__clf__feature_selection__estimator__min_impurity_split\n",
      "estimator__clf__feature_selection__estimator__min_samples_leaf\n",
      "estimator__clf__feature_selection__estimator__min_samples_split\n",
      "estimator__clf__feature_selection__estimator__min_weight_fraction_leaf\n",
      "estimator__clf__feature_selection__estimator__n_estimators\n",
      "estimator__clf__feature_selection__estimator__n_jobs\n",
      "estimator__clf__feature_selection__estimator__oob_score\n",
      "estimator__clf__feature_selection__estimator__random_state\n",
      "estimator__clf__feature_selection__estimator__verbose\n",
      "estimator__clf__feature_selection__estimator__warm_start\n",
      "estimator__clf__feature_selection__estimator\n",
      "estimator__clf__feature_selection__max_features\n",
      "estimator__clf__feature_selection__norm_order\n",
      "estimator__clf__feature_selection__prefit\n",
      "estimator__clf__feature_selection__threshold\n",
      "estimator__clf__log__C\n",
      "estimator__clf__log__class_weight\n",
      "estimator__clf__log__dual\n",
      "estimator__clf__log__fit_intercept\n",
      "estimator__clf__log__intercept_scaling\n",
      "estimator__clf__log__max_iter\n",
      "estimator__clf__log__multi_class\n",
      "estimator__clf__log__n_jobs\n",
      "estimator__clf__log__penalty\n",
      "estimator__clf__log__random_state\n",
      "estimator__clf__log__solver\n",
      "estimator__clf__log__tol\n",
      "estimator__clf__log__verbose\n",
      "estimator__clf__log__warm_start\n",
      "estimator\n",
      "fit_params\n",
      "iid\n",
      "n_jobs\n",
      "param_grid\n",
      "pre_dispatch\n",
      "refit\n",
      "return_train_score\n",
      "scoring\n",
      "verbose\n"
     ]
    }
   ],
   "source": [
    "for para in grid_search_item.get_params().keys():\n",
    "    print(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "learning to rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from math import sin\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "butIRegress = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('feats', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('text', Pipeline(memory=None,\n",
       "     steps=[('selector', ItemSelectorText(key='post_body')), ('cv', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='c...alty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]))])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2 = Pipeline([\n",
    "    \n",
    "    ('feats', FeatureUnion([\n",
    "        ('text', Pipeline([\n",
    "            ('selector', ItemSelectorText(key='post_body')),\n",
    "            ('cv', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "             ])),\n",
    "        ('liwc_features', Pipeline([\n",
    "                ('selector', get_liwc_data) ])),\n",
    "        ('empath_features', Pipeline([\n",
    "                ('selector', get_empath_data)])),\n",
    "        ('tag_features', Pipeline([\n",
    "                ('selector', get_tags)])),\n",
    "#         ('readability_features', Pipeline([\n",
    "#                 ('selector', get_read)])),\n",
    "        ('selector1', ItemSelector(key='motivations')),\n",
    "\n",
    "        ('selector5', ItemSelector(key='healthWordCount')),\n",
    "        ('selector6', ItemSelector(key='mentionMethods')),\n",
    "             ])),\n",
    "    \n",
    "       ('clf', Pipeline([\n",
    "       ('scale', StandardScaler(with_mean=False)),\n",
    "       ('feature_selection', SelectFromModel(RandomForestClassifier(random_state=20))),\n",
    "\n",
    "      ('log', LogisticRegression()),\n",
    "#      ('gbn', GaussianNB()),\n",
    "\n",
    "         ])),\n",
    "])\n",
    "parameters = [{'feature_selection__estimator__max_depth': [5,10,20], 'feature_selection__estimator__max_leaf_nodes': [50, 100, 200]}]\n",
    "\n",
    "    \n",
    "estimator = GridSearchCV(pipe2, parameters, scoring='roc_auc')\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# pred = pipe1.predict(X_test)\n",
    "# print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Pipeline' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-8d0b72c3e497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipe2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Pipeline' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "pipe2.best_estimator_.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "÷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
