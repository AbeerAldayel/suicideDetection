{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import re\n",
    "from tika import parser #parse pdf text\n",
    "import numpy as np\n",
    "from empath import Empath # similar to LIWC\n",
    "import math\n",
    "pd.options.mode.chained_assignment = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script generates posting frequency feature, empath and dictionary feature\n",
    "for posting frequency, see example out[303]\n",
    "postingFrequency: number of posts in this file\n",
    "postingInterval: intervals between previous and later posts (days) \n",
    "generalMoreFreq: is the posting behavior becomes more frequent\n",
    "generalWordCount: mean word count of the posts in each user\n",
    "Note: these features are built on user level\n",
    "\n",
    "We can also select posts than contain certain diction see out[306]\n",
    "MH is a file with posts contain mentall illness, symptoms keywords \n",
    "then we compute the posting behaviors in regard to these posts\n",
    "the features are:\n",
    "healthPostingFrequency\thealthPostingInterval\thealthMoreFreq\n",
    "\n",
    "Empath In[501]\n",
    "this is the empath features on post level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/lucia/phd_work/suicideDetection/'\n",
    "#path = '/home/lucia/phd_work/shareTask/CLpsych/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos1 = pd.read_csv(  path +'/data_sample_clpsych19/user10146.posts.csv')\n",
    "pos2 = pd.read_csv(  path +'/data_sample_clpsych19/user10276.posts.csv')\n",
    "neg1 = pd.read_csv( path +'/data_sample_clpsych19/user-29175.posts.csv')\n",
    "neg2 = pd.read_csv( path +'/data_sample_clpsych19/user-44823.posts.csv')\n",
    "file = pos1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275dra</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-02 22:05:47</td>\n",
       "      <td>OpTicGaming</td>\n",
       "      <td>[Throwback: BO2 MLG Anaheim] WHO'S THE BEST IN...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2760t9</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-03 02:12:28</td>\n",
       "      <td>ForeverAloneDating</td>\n",
       "      <td>20 [M4F] WA - Looking for the player 2 to my p...</td>\n",
       "      <td>What's going on everybody? My name is Waf3l, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>277upp</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-03 17:33:23</td>\n",
       "      <td>CoDCompetitive</td>\n",
       "      <td>Who is your favorite Pro Team?</td>\n",
       "      <td>I know we have the flair to back it up, but I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27cmpe</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-05 02:53:13</td>\n",
       "      <td>r4r</td>\n",
       "      <td>20 [M4F] Seattle - Can you be my \"It Girl\"?</td>\n",
       "      <td>What's going on everybody? My name is Waf3l, b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id  user_id            timestamp           subreddit  \\\n",
       "1  275dra    10146  2014-06-02 22:05:47         OpTicGaming   \n",
       "2  2760t9    10146  2014-06-03 02:12:28  ForeverAloneDating   \n",
       "3  277upp    10146  2014-06-03 17:33:23      CoDCompetitive   \n",
       "4  27cmpe    10146  2014-06-05 02:53:13                 r4r   \n",
       "\n",
       "                                          post_title  \\\n",
       "1  [Throwback: BO2 MLG Anaheim] WHO'S THE BEST IN...   \n",
       "2  20 [M4F] WA - Looking for the player 2 to my p...   \n",
       "3                     Who is your favorite Pro Team?   \n",
       "4        20 [M4F] Seattle - Can you be my \"It Girl\"?   \n",
       "\n",
       "                                           post_body  \n",
       "1                                                NaN  \n",
       "2  What's going on everybody? My name is Waf3l, b...  \n",
       "3  I know we have the flair to back it up, but I ...  \n",
       "4  What's going on everybody? My name is Waf3l, b...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file1 = pd.concat([pos1, pos2], ignore_index= True)\n",
    "# file2 = pd.concat([neg1, neg2], ignore_index= True)\n",
    "# file = pd.concat([file1, file2], ignore_index= True) \n",
    "#convert timestamp to time, sorted the table according to time \n",
    "file['timestamp'] = file['timestamp'].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "file[1:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we build features on user level, for each user, we have Number of annotation unit, number of posts in sucideWatch, average length of post in suicideWatch, frequency of posting in all subreddit, frequency of posting in suicideWatch, posts mentioned mental illness, sentiment in posts (LIWC), number of posts without content, posts that mention suicide methods(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a dictionary that stores the posting pattern "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PostingFreq(file):\n",
    "    timeFreq = {} #dictionary that shows the average time a user post sth \n",
    "    preUser = None #previous user \n",
    "    preTime = None #posting time of the previous day\n",
    "    dayVec = [] #a vector that shows the time difference between a previous day and the day after\n",
    "    \n",
    "    for userid, time in zip(file['user_id'], file['timestamp']):\n",
    "        if preTime is None:\n",
    "            freq = time \n",
    "        elif userid == preUser:\n",
    "            #freq = previous day - day after\n",
    "            freq = datetime.strptime(time, \"%Y-%m-%d %H:%M:%S\") - datetime.strptime(preTime, \"%Y-%m-%d %H:%M:%S\")\n",
    "            dayVec.append(freq.days) \n",
    "            timeFreq[userid] = dayVec\n",
    "            \n",
    "        elif type(freq) is not str: # freq is not a datetime object if there is one case only\n",
    "            dayVec = [freq.days] \n",
    "\n",
    "        preTime = time \n",
    "        preUser = userid\n",
    "        \n",
    "    return timeFreq\n",
    "\n",
    "postingFrequency = PostingFreq(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 0, 1, 0, 3, 8, 1, 0, 0, 1, 0, 0, 4, 1, 32, 0, 2, 25, 17, 6, 7, 3, 5, 28, 3, 0, 6, 70, 56, 2, 0, 4, 89, 3, 12, 9]\n",
      "[9, 0, 0, 4, 1, 7, 5, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 2, 5, 6, 5, 1, 4, 0, 0, 0, 1, 5, 2, 4, 0, 3, 36, 2, 1, 1, 0, 5, 9, 2, 1, 0, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 10, 4, 1, 19, 0, 19, 23, 34, 14, 8, 12, 23, 70, 1, 0, 1, 0, 0, 7, 8, 2, 2, 6, 3, 9, 11, 6, 0, 0, 0, 0, 0, 0, 0, 8, 12, 1, 9, 4, 1, 0, 0, 13, 3, 0, 27, 2, 2, 4, 21, 1, 11, 20, 0, 13, 43, 3, 4, 9, 1, 2, 2, 4, 48, 25, 2, 9, 7, 0, 2, 11, 10, 2, 70, 114, 1, 1, 12, 11, 148]\n",
      "[148, 2, 1, 0, 26, 612, 30, 67, 122, 0, 19, 0, 8, 2, 5, 2, 0, 22]\n",
      "[22, 0, 1, 0, 24, 14, 22, 10, 6, 6, 63, 107, 112, 17, 36, 4, 1, 0, 20, 22, 0, 12, 0, 37, 0, 20, 3, 100, 15, 18, 24, 32, 335, 33, 8, 31, 137, 162, 0, 11, 1, 7, 9, 3, 0, 0, 0, 0, 4, 2, 0, 8, 5, 2, 5, 4, 0, 6, 8, 3, 2, 2, 0, 7, 10, 2, 0, 3, 6, 0, 5, 1, 0, 16]\n"
     ]
    }
   ],
   "source": [
    "for item in postingFrequency:\n",
    "    print(postingFrequency[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10.837837837837839]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#here we compute the mean of posting interval \n",
    "def computeMean(dictionary):\n",
    "    mean = []\n",
    "    for i in dictionary:\n",
    "        mean.append((sum(dictionary[i])/len(dictionary[i])))\n",
    "    return mean\n",
    "        \n",
    "mean = computeMean(postingFrequency)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can also get the frequency \n",
    "def computeFreq(dictionary):\n",
    "    freq = []\n",
    "    for i in dictionary:\n",
    "        freq.append(len(dictionary[i])+1)\n",
    "    return freq\n",
    "\n",
    "freq = computeFreq(postingFrequency)\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interval mean does not tell whether the user have increased the posting frequency, so here we will see if the posting behaviour is getting more frequent. define a sliding window to compare frequencies, we can define the size of the window, if the last window (closest to data extaction time) is 1 sd below the mean, we assign '1' to indicate the author post more frequent recently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>postingFrequency</th>\n",
       "      <th>postingInterval</th>\n",
       "      <th>generalMoreFreq</th>\n",
       "      <th>generalWordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10146.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.837838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.473684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  postingFrequency  postingInterval  generalMoreFreq  \\\n",
       "0  10146.0              38.0        10.837838              1.0   \n",
       "\n",
       "   generalWordCount  \n",
       "0         83.473684  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeInterval = [8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
    "def getSlidingWindow(array, window):\n",
    "    ret = []\n",
    "    i = 0\n",
    "    j = window\n",
    "    while j < len(array):\n",
    "        ret.append((sum(array[i:j]), i,j))\n",
    "        i = i+1\n",
    "        j = j+1\n",
    "    ret.sort()\n",
    "    ret.reverse()\n",
    "    return ret\n",
    "\n",
    "#if the last time window is 1sd below the mean\n",
    "def isMoreFrequent(array, window):\n",
    "    meanlist = []\n",
    "    for item in getSlidingWindow(array, window):\n",
    "        meanlist.append(item[0])\n",
    "    meanL = np.mean(meanlist)\n",
    "    std = np.std(meanlist)\n",
    "    result = []\n",
    "    indexL = []\n",
    "    for index, item in enumerate(getSlidingWindow(array, window)):\n",
    "        \n",
    "        if item[0]  <= meanL - std:\n",
    "            indexL.append(index)       \n",
    "    length = len(getSlidingWindow(array, window))-1\n",
    "    if length != 0:\n",
    "        if length in indexL:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "def getMoreFrequent(postingFrequency, window):\n",
    "    results = []\n",
    "    for item in postingFrequency:\n",
    "        result = isMoreFrequent(postingFrequency[item],window)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def stringCount(text):\n",
    "    count = 0\n",
    "    for item in text.split():\n",
    "        count = count + 1\n",
    "    return count \n",
    "\n",
    "#this function return a frequency feature matrix \n",
    "def getFrequencyFeature(file, intervalName, freqName, isMoreFreq, PostWordCount, SlideWindow): #input df that you need to count the posting frequency and interval \n",
    "    #dictionary that shows the average time a user post sth \n",
    "    postingFrequency = PostingFreq(file)\n",
    "    #mean of posting interval\n",
    "    mean = computeMean(postingFrequency)\n",
    "    # is the posting behaviour becoming more frequent\n",
    "    MoreFreq = getMoreFrequent(postingFrequency, SlideWindow)\n",
    "    #comupte number of postings\n",
    "    freq = computeFreq(postingFrequency)\n",
    "    #mean wordcount in post\n",
    "    PostCount = file.groupby(['user_id']).size().reset_index(name = 'counts')\n",
    "    file = pd.merge(PostCount, file, on='user_id')\n",
    "    MoreThanOnePost = file[file.counts > 1]\n",
    "    MoreThanOnePost['wordCount'] = MoreThanOnePost['post_body'].apply(lambda x: stringCount(str(x)))\n",
    "    wordCount = MoreThanOnePost.groupby(['user_id'])['wordCount'].mean().reset_index(name = 'counts')\n",
    "    \n",
    "    #append all the features\n",
    "    ProtoDf = np.vstack((list(postingFrequency.keys()),freq))\n",
    "    ProtoDf = np.vstack((ProtoDf, mean))\n",
    "    ProtoDf = np.vstack((ProtoDf, MoreFreq))\n",
    "    ProtoDf = np.vstack((ProtoDf, wordCount.counts))\n",
    "    df = pd.DataFrame(ProtoDf)\n",
    "    featureTable = df.T \n",
    "    featureTable.columns = ['user_id',freqName,intervalName, isMoreFreq, PostWordCount]\n",
    "    \n",
    "    #this part only triggers when there are users posted 1 post\n",
    "    onePost = PostCount[PostCount.counts == 1]\n",
    "    one = file[file.counts == 1]\n",
    "    #now create a table with this one post id, assign NaN to interval and 1 to posting Frequency\n",
    "    if one.empty is False: \n",
    "        one['wordCount'] = one['post_body'].apply(lambda x: stringCount(str(x)))\n",
    "        onePost[intervalName] = 0\n",
    "        onePost[isMoreFreq] = 0\n",
    "        onePost[PostWordCount] = one.wordCount\n",
    "        onePost.columns = ['user_id', freqName, intervalName, isMoreFreq, PostWordCount]\n",
    "        featureTable = featureTable.append(onePost,ignore_index=True)\n",
    "    \n",
    "    return featureTable\n",
    "\n",
    "FreqTable = getFrequencyFeature(file, 'postingInterval','postingFrequency', 'generalMoreFreq', 'generalWordCount', 6)\n",
    "FreqTable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of    user_id     counts\n",
       "0    10146  83.473684>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file['wordCount'] = file['post_body'].apply(lambda x: stringCount(str(x)))\n",
    "wordCount = file.groupby(['user_id'])['wordCount'].mean().reset_index(name = 'counts')\n",
    "wordCount.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check posting behavior on different subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "      <th>wordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2985q5</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-27 08:15:28</td>\n",
       "      <td>SuicideWatch</td>\n",
       "      <td>I'm done.</td>\n",
       "      <td>I'm just done with life. I'm nothing but a scr...</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  user_id            timestamp     subreddit post_title  \\\n",
       "14  2985q5    10146  2014-06-27 08:15:28  SuicideWatch  I'm done.   \n",
       "\n",
       "                                            post_body  wordCount  \n",
       "14  I'm just done with life. I'm nothing but a scr...         80  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicideWatch = file[file['subreddit'].str.contains(\"SuicideWatch\")]\n",
    "suicideWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "DataError",
     "evalue": "No numeric types to aggregate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-94aee992d565>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetFrequencyFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuicideWatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SuicidePostingInterval'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'SuicidePostingFrequency'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SuicideMoreFreq'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SuicideWordCount'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-cb84f4423b0a>\u001b[0m in \u001b[0;36mgetFrequencyFeature\u001b[0;34m(file, intervalName, freqName, isMoreFreq, PostWordCount, SlideWindow)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mMoreThanOnePost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcounts\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mMoreThanOnePost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wordCount'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoreThanOnePost\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'post_body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstringCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mwordCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMoreThanOnePost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wordCount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'counts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;31m#append all the features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \u001b[0mnv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_groupby_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'numeric_only'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cython_agg_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGroupByError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[0;34m(self, how, alt, numeric_only)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 836\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No numeric types to aggregate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_aggregated_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDataError\u001b[0m: No numeric types to aggregate"
     ]
    }
   ],
   "source": [
    "getFrequencyFeature(suicideWatch, 'SuicidePostingInterval','SuicidePostingFrequency', 'SuicideMoreFreq', 'SuicideWordCount', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a dictionary with all mental illness names and symptoms, we downloaded a pdf file from file:///home/lucia/phd_work/shareTask/CLpsych/glossary-mental-health-i.pdf \n",
    "we extract the terms (starts with capital letter), then we mannually selected the terms and save it as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read pdf file \n",
    "raw = parser.from_file(path+ '/dictionaries/glossary-mental-health.pdf')\n",
    "t = re.findall('([A-Z][a-z]+)', raw['content'])\n",
    "Psylist = set(t)\n",
    "#save list as txt\n",
    "# with open(\"/home/lucia/phd_work/shareTask/CLpsych/psyList.txt\", \"w\") as output:\n",
    "#     output.write(str(Psylist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read adjusted mental illness glossary list\n",
    "def readDictionaries(filePath):\n",
    "    with open(filePath) as f:\n",
    "        myList = [x.strip().replace(\"'\",\"\").lower() for x in f.read().split(\",\")]\n",
    "        #print(Psylist)\n",
    "    return myList\n",
    "\n",
    "PsyList = readDictionaries(path +'/dictionaries/psyList.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opioid'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PsyList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>Psy_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26u0eb</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-05-30 00:13:59</td>\n",
       "      <td>dating</td>\n",
       "      <td>am i doing something wrong?</td>\n",
       "      <td>as the title says, i have no clue what i'm doi...</td>\n",
       "      <td>141</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275dra</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-02 22:05:47</td>\n",
       "      <td>opticgaming</td>\n",
       "      <td>[throwback: bo2 mlg anaheim] who's the best in...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2760t9</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-03 02:12:28</td>\n",
       "      <td>foreveralonedating</td>\n",
       "      <td>20 [m4f] wa - looking for the player 2 to my p...</td>\n",
       "      <td>what's going on everybody? my name is waf3l, b...</td>\n",
       "      <td>611</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id  user_id            timestamp           subreddit  \\\n",
       "0  26u0eb    10146  2014-05-30 00:13:59              dating   \n",
       "1  275dra    10146  2014-06-02 22:05:47         opticgaming   \n",
       "2  2760t9    10146  2014-06-03 02:12:28  foreveralonedating   \n",
       "\n",
       "                                          post_title  \\\n",
       "0                        am i doing something wrong?   \n",
       "1  [throwback: bo2 mlg anaheim] who's the best in...   \n",
       "2  20 [m4f] wa - looking for the player 2 to my p...   \n",
       "\n",
       "                                           post_body  wordCount  Psy_title  \n",
       "0  as the title says, i have no clue what i'm doi...        141      False  \n",
       "1                                               NULL          1      False  \n",
       "2  what's going on everybody? my name is waf3l, b...        611      False  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean text, lower cases\n",
    "file['post_title'] = file['post_title'].apply(lambda x: x.lower())\n",
    "file['subreddit'] = file['subreddit'].apply(lambda x: x.lower())\n",
    "file['post_body'] = file['post_body'].apply(lambda x: x.lower() if type(x) is str else 'NULL')\n",
    "file[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>Psy_title</th>\n",
       "      <th>Psy_body</th>\n",
       "      <th>Psy_subre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26u0eb</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-05-30 00:13:59</td>\n",
       "      <td>dating</td>\n",
       "      <td>am i doing something wrong?</td>\n",
       "      <td>as the title says, i have no clue what i'm doi...</td>\n",
       "      <td>141</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>275dra</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-02 22:05:47</td>\n",
       "      <td>opticgaming</td>\n",
       "      <td>[throwback: bo2 mlg anaheim] who's the best in...</td>\n",
       "      <td>NULL</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2760t9</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-03 02:12:28</td>\n",
       "      <td>foreveralonedating</td>\n",
       "      <td>20 [m4f] wa - looking for the player 2 to my p...</td>\n",
       "      <td>what's going on everybody? my name is waf3l, b...</td>\n",
       "      <td>611</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  post_id  user_id            timestamp           subreddit  \\\n",
       "0  26u0eb    10146  2014-05-30 00:13:59              dating   \n",
       "1  275dra    10146  2014-06-02 22:05:47         opticgaming   \n",
       "2  2760t9    10146  2014-06-03 02:12:28  foreveralonedating   \n",
       "\n",
       "                                          post_title  \\\n",
       "0                        am i doing something wrong?   \n",
       "1  [throwback: bo2 mlg anaheim] who's the best in...   \n",
       "2  20 [m4f] wa - looking for the player 2 to my p...   \n",
       "\n",
       "                                           post_body  wordCount  Psy_title  \\\n",
       "0  as the title says, i have no clue what i'm doi...        141      False   \n",
       "1                                               NULL          1      False   \n",
       "2  what's going on everybody? my name is waf3l, b...        611      False   \n",
       "\n",
       "   Psy_body  Psy_subre  \n",
       "0     False      False  \n",
       "1     False      False  \n",
       "2     False       True  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if words find in text, print 'T', otherwise 'F'\n",
    "def findText(text, wordList):\n",
    "    for item in wordList:\n",
    "        if item in text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def subsetDictPosts(file, dictionary, newTitle, newBody, newSubreddit):\n",
    "    file[newTitle] = file.apply(lambda row: True if findText(row[\"post_title\"], dictionary) else False, axis=1)\n",
    "    file[newBody] = file.apply(lambda row: True if findText(row[\"post_body\"], dictionary) else False, axis=1)\n",
    "    file[newSubreddit] = file.apply(lambda row: True if findText(row[\"subreddit\"], dictionary) else False, axis=1)\n",
    "\n",
    "subsetDictPosts(file, PsyList, 'Psy_title', 'Psy_body', 'Psy_subre')\n",
    "file[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#these are the posts contain words in the dictionary\n",
    "MH = file[(file['Psy_body'] == True) | (file['Psy_title'] == True) | (file['Psy_subre'] == True)]\n",
    "MH.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2920: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/lucia/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>healthPostingFrequency</th>\n",
       "      <th>healthPostingInterval</th>\n",
       "      <th>healthMoreFreq</th>\n",
       "      <th>healthWordCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10146.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10276.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  healthPostingFrequency  healthPostingInterval  healthMoreFreq  \\\n",
       "0  10146.0                     4.0              36.666667             0.0   \n",
       "1  10276.0                    28.0              22.000000             1.0   \n",
       "\n",
       "   healthWordCount  \n",
       "0       173.250000  \n",
       "1        77.777778  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now we see whether users post mental illness related things more frequent, we can merge this with feature matrix\n",
    "#later on \n",
    "MHF = getFrequencyFeature(MH, 'healthPostingInterval','healthPostingFrequency', 'healthMoreFreq', 'healthWordCount',4)\n",
    "MHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now we can merge the features \n",
    "FreqFea = pd.merge(FreqTable, MHF, on ='user_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check suicide methods, we created a dictionary suicideMethods.txt to check methods and tools mention in the posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_body</th>\n",
       "      <th>wordCount</th>\n",
       "      <th>Psy_title</th>\n",
       "      <th>Psy_body</th>\n",
       "      <th>Psy_subre</th>\n",
       "      <th>med_title</th>\n",
       "      <th>med_body</th>\n",
       "      <th>med_subre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2985q5</td>\n",
       "      <td>10146</td>\n",
       "      <td>2014-06-27 08:15:28</td>\n",
       "      <td>suicidewatch</td>\n",
       "      <td>i'm done.</td>\n",
       "      <td>i'm just done with life. i'm nothing but a scr...</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id  user_id            timestamp     subreddit post_title  \\\n",
       "14  2985q5    10146  2014-06-27 08:15:28  suicidewatch  i'm done.   \n",
       "\n",
       "                                            post_body  wordCount  Psy_title  \\\n",
       "14  i'm just done with life. i'm nothing but a scr...         80      False   \n",
       "\n",
       "    Psy_body  Psy_subre  med_title  med_body  med_subre  \n",
       "14     False       True      False      True      False  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = readDictionaries(path + '/dictionaries/suicideMethods.txt')\n",
    "subsetDictPosts(file, methods, 'med_title', 'med_body', 'med_subre')\n",
    "#we only check if suicidewatch posts contain these keywords\n",
    "suicideWatch = file[file['subreddit'] == 'suicidewatch']\n",
    "med = suicideWatch[(suicideWatch['med_body'] == True) | (suicideWatch['med_title'] == True)]\n",
    "med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def checkDictFea(file):\n",
    "    file.drop_duplicates(subset=['user_id'], keep=False)\n",
    "    newFea = file[['user_id']]\n",
    "    newFea['mentionMethods'] = 1\n",
    "    return newFea\n",
    "\n",
    "methods = checkDictFea(med)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>postingFrequency</th>\n",
       "      <th>postingInterval</th>\n",
       "      <th>generalMoreFreq</th>\n",
       "      <th>generalWordCount</th>\n",
       "      <th>healthPostingFrequency</th>\n",
       "      <th>healthPostingInterval</th>\n",
       "      <th>healthMoreFreq</th>\n",
       "      <th>healthWordCount</th>\n",
       "      <th>mentionMethods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10146.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>10.837838</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.864865</td>\n",
       "      <td>4.0</td>\n",
       "      <td>36.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173.250000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10276.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>7.352941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.055556</td>\n",
       "      <td>28.0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.777778</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-29175.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>59.222222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83.473684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-44823.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>21.432432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.183007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  postingFrequency  postingInterval  generalMoreFreq  \\\n",
       "0  10146.0              38.0        10.837838              1.0   \n",
       "1  10276.0             154.0         7.352941              0.0   \n",
       "2 -29175.0              19.0        59.222222              1.0   \n",
       "3 -44823.0              75.0        21.432432              0.0   \n",
       "\n",
       "   generalWordCount  healthPostingFrequency  healthPostingInterval  \\\n",
       "0         26.864865                     4.0              36.666667   \n",
       "1         13.055556                    28.0              22.000000   \n",
       "2         83.473684                     0.0               0.000000   \n",
       "3         26.183007                     0.0               0.000000   \n",
       "\n",
       "   healthMoreFreq  healthWordCount  mentionMethods  \n",
       "0             0.0       173.250000             1.0  \n",
       "1             1.0        77.777778             0.0  \n",
       "2             0.0         0.000000             0.0  \n",
       "3             0.0         0.000000             0.0  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FreqFea = pd.merge(FreqFea, methods, on ='user_id', how = 'left')\n",
    "FreqFea.fillna(0, inplace=True)\n",
    "FreqFea.to_csv(path+'FreqFea.csv')\n",
    "FreqFea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will generate sentiment and topic features for each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>achievement</th>\n",
       "      <th>shame</th>\n",
       "      <th>affection</th>\n",
       "      <th>aggression</th>\n",
       "      <th>anger</th>\n",
       "      <th>cheerfulness</th>\n",
       "      <th>disappointment</th>\n",
       "      <th>disgust</th>\n",
       "      <th>dispute</th>\n",
       "      <th>emotional</th>\n",
       "      <th>...</th>\n",
       "      <th>attractive</th>\n",
       "      <th>banking</th>\n",
       "      <th>money</th>\n",
       "      <th>body</th>\n",
       "      <th>health</th>\n",
       "      <th>injury</th>\n",
       "      <th>medical_emergency</th>\n",
       "      <th>death</th>\n",
       "      <th>friends</th>\n",
       "      <th>help</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10146</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>0.007217</td>\n",
       "      <td>0.001227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10276</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.00147</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.002654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         achievement     shame  affection  aggression     anger  cheerfulness  \\\n",
       "user_id                                                                         \n",
       "10146            0.0  0.006250   0.002455    0.000818  0.000000           0.0   \n",
       "10276            0.0  0.002518   0.000123    0.000000  0.000123           0.0   \n",
       "\n",
       "         disappointment  disgust   dispute  emotional    ...     attractive  \\\n",
       "user_id                                                  ...                  \n",
       "10146          0.000000      0.0  0.000409   0.000000    ...       0.004762   \n",
       "10276          0.000311      0.0  0.000313   0.001335    ...       0.000428   \n",
       "\n",
       "          banking     money      body    health   injury  medical_emergency  \\\n",
       "user_id                                                                       \n",
       "10146    0.000409  0.000409  0.000000  0.000818  0.00000           0.000818   \n",
       "10276    0.000544  0.000544  0.002519  0.003040  0.00147           0.003562   \n",
       "\n",
       "            death   friends      help  \n",
       "user_id                                \n",
       "10146    0.003534  0.007217  0.001227  \n",
       "10276    0.002655  0.001384  0.002654  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon = Empath()\n",
    "def getEmpath(file):\n",
    "    empathy = {}\n",
    "    for item, postid in zip(file['post_body'],file['post_id']):\n",
    "        empathy[postid] = lexicon.analyze(item, normalize=True) \n",
    "    empathyFea = pd.DataFrame.from_dict(empathy)\n",
    "    empathyFea = empathyFea.T\n",
    "    empathyFea['post_id'] = empathyFea.index\n",
    "    return empathyFea\n",
    "\n",
    "def getDictionsEmpath(file, PsyList, EmpathVars):\n",
    "    subsetDictPosts(file, PsyList, 'Psy_title', 'Psy_body', 'Psy_subre')\n",
    "    subset = file[(file['Psy_body'] == True) | (file['Psy_title'] == True) | (file['Psy_subre'] == True)]\n",
    "    Features = getEmpath(subset)\n",
    "    Fea = pd.merge(subset, Features, on = 'post_id', how ='left')\n",
    "    empathFea = Fea[EmpathVars]\n",
    "    #aggregate to user level \n",
    "    empath = empathFea.groupby('user_id').mean()\n",
    "    return empath\n",
    "\n",
    "#define dictionary and the empath topics you want to retain\n",
    "EmpathVars = ['post_id','user_id', 'achievement', 'shame', 'affection', 'aggression', 'anger', 'cheerfulness', 'disappointment', 'disgust', 'dispute', 'emotional', 'fear', 'fun', 'hate', 'joy', 'love', 'negative_emotion', 'nervousness', 'optimism', 'pain', 'positive_emotion', \n",
    "                 'suffering', 'alcohol', 'appearance', 'attractive', 'banking', 'money', 'body', 'health', 'injury', 'medical_emergency', 'death', 'friends', 'help']\n",
    "fea = getDictionsEmpath(file, PsyList, EmpathVars)\n",
    "fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "skip-gram/infersent preserve knowledge in sentence level, cluster the posts with sentence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score,\\\n",
    "recall_score, confusion_matrix, classification_report, accuracy_score \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import svm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sys import argv\n",
    "import gc\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_vec, y, test_size=0.30, random_state=30)\n",
    "###grid search\n",
    "#SMOTE: Synthetic Minority Over-sampling Technique\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5, random_state = 0)\n",
    "clf = make_pipeline(smote_enn, SGDClassifier(max_iter= 1000),StandardScaler())\n",
    "parameters = [{'sgdclassifier__alpha': [0.01, 0.05, 0.001, 0.005], 'sgdclassifier__class_weight':['balanced'],\n",
    "                'sgdclassifier__loss': ['hinge','log','modified_huber','squared_hinge', 'perceptron'], \n",
    "                 'sgdclassifier__penalty':['none','l1','l2']}]                   \n",
    "grid_search_item = GridSearchCV(estimator = clf,\n",
    "                          param_grid = parameters,\n",
    "                           cv =  cv,\n",
    "                           scoring = 'accuracy',\n",
    "                           n_jobs = -1)\n",
    "grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "print('Best scores and best parameters')\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "  \n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Naive bayes\n",
    "Create a Gaussian Classifier\n",
    "model = GaussianNB()\n",
    "If continuous features do not have normal distribution, we should use transformation or different methods to convert it in normal distribution.\n",
    "If test data set has zero frequency issue, apply smoothing techniques “Laplace Correction” to predict the class of test data set.\n",
    "Remove correlated features, as the highly correlated features are voted twice in the model and it can lead to over inflating importance.\n",
    "\n",
    "Try\n",
    "Bernoulli Naive Bayes \n",
    "Features represented by the presence of a term "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
