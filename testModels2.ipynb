{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score,\\\n",
    "recall_score, confusion_matrix, classification_report, accuracy_score \n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sys import argv\n",
    "import gc\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import make_pipeline, Pipeline\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportantFea(X, y):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=35)\n",
    "\t\n",
    "\tmodel = ExtraTreesClassifier(random_state = 0)\n",
    "\tmodel.fit(X_train, y_train)\n",
    "\t#print(model.feature_importances_)\n",
    "\n",
    "\tprint(\"Feature ranking:\")\n",
    "\n",
    "\timportances = model.feature_importances_\n",
    "\tstd = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "\tindices = np.argsort(importances)[::-1]\n",
    "\tfor f in range(X.shape[1]):\n",
    "\t\tprint(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "\tfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "\tfeat_importances.nlargest(20).plot(kind='barh')\n",
    "\tplt.show()\n",
    "\n",
    "\tfea_df = pd.DataFrame(feat_importances)\n",
    "\tfea_df['features'] = fea_df.index\n",
    "\tfea_df.columns = ['importance','features']\n",
    "\tfea_df.to_csv(path + 'topFea.csv')\n",
    "\treturn fea_df\n",
    "\n",
    "def ExTreeClassifier(X,y):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=35)\n",
    "\tsmote_enn = SMOTEENN(random_state=42)\n",
    "\trf = make_pipeline(smote_enn, StandardScaler(), ExtraTreesClassifier(random_state = 0))\n",
    "\tcv = StratifiedKFold(n_splits=5, random_state = 0)\n",
    "\n",
    "\tparameters = [{'extratreesclassifier__max_features':['auto','sqrt','log2'], 'extratreesclassifier__class_weight':['balanced'], \n",
    "\t             'extratreesclassifier__max_leaf_nodes':[10,50,100], 'extratreesclassifier__max_depth':[2,5,10,20], 'extratreesclassifier__n_estimators' : [50,100,200,300,400]}]\n",
    "\t             \n",
    "\tgrid_search_item = GridSearchCV(rf,\n",
    "\t                            param_grid = parameters,\n",
    "\t                             scoring = 'accuracy',\n",
    "\t                             cv = cv,\n",
    "\t                             n_jobs = -1)\n",
    "\n",
    "\tgrid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "\tprint('Best scores and best parameters')\n",
    "\tprint(grid_search.best_score_)\n",
    "\tprint(grid_search.best_params_)\n",
    "\n",
    "\ty_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "\tprint(classification_report(y_true, y_pred))\n",
    "\n",
    "\timportance = grid_search.best_estimator_.steps[2][1].feature_importances_\n",
    "\n",
    "\tfeat_importances = pd.Series(importance, index=X.columns)\n",
    "\tfeat_importances.nlargest(20).plot(kind='barh')\n",
    "\tplt.show()\n",
    "\n",
    "\tfea_df = pd.DataFrame(feat_importances)\n",
    "\tfea_df['features'] = fea_df.index\n",
    "\tfea_df.columns = ['importance','features']\n",
    "\tfea_df.to_csv(path + 'topFea.csv')\n",
    "\treturn fea_df\n",
    "\n",
    "def RFfeatureSel(X_train,y_train):\n",
    "\t\n",
    "\tsmote_enn = SMOTEENN(random_state=42)\n",
    "\trf = make_pipeline(smote_enn, StandardScaler(), RandomForestClassifier(random_state=20))\n",
    "\tcv = StratifiedKFold(n_splits=5, random_state = 0)\n",
    "\n",
    "\tparameters = [{'randomforestclassifier__max_features':['auto','sqrt','log2'], 'randomforestclassifier__class_weight':['balanced'], \n",
    "\t             'randomforestclassifier__max_leaf_nodes':[10,50,100], 'randomforestclassifier__max_depth':[2,5,10,20], 'randomforestclassifier__n_estimators' : [50,100,200,300,400]}]\n",
    "\t             \n",
    "\tgrid_search_item = GridSearchCV(rf,\n",
    "\t                            param_grid = parameters,\n",
    "\t                             scoring = 'accuracy',\n",
    "\t                             cv = cv,\n",
    "\t                             n_jobs = -1)\n",
    "\n",
    "\tgrid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "\tprint('Best scores and best parameters')\n",
    "\tprint(grid_search.best_score_)\n",
    "\tprint(grid_search.best_params_)\n",
    "\n",
    "\n",
    "\timportance = grid_search.best_estimator_.steps[2][1].feature_importances_\n",
    "\n",
    "\tfeat_importances = pd.Series(importance, index=X_train.columns)\n",
    "\tfeat_importances.nlargest(20).plot(kind='barh')\n",
    "\tplt.show()\n",
    "\n",
    "\tfea_df = pd.DataFrame(feat_importances)\n",
    "\tfea_df['features'] = fea_df.index\n",
    "\tfea_df.columns = ['importance','features']\n",
    "\tfea_df.to_csv(path + 'topFea.csv')\n",
    "\treturn fea_df\n",
    "\n",
    "\n",
    "def selectFea(FeaImportant, Nfea):\n",
    "    sortFea = FeaImportant.sort_values(by=['importance'],ascending=False)\n",
    "    select = sortFea[1:Nfea]   \n",
    "    return select.features.values\n",
    "\n",
    "\n",
    "def SVMclassifier(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=35)\n",
    "\n",
    "    smote_enn = SMOTEENN(random_state=42)\n",
    "    #ps = PredefinedSplit(test_fold=y_test)\n",
    "    cv = StratifiedKFold(n_splits=5, random_state = 0)\n",
    "    svc = make_pipeline(StandardScaler(), svm.SVC())\n",
    "    parameters = [{'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'svc__gamma': [0.01, 0.001, 0.0001],\n",
    "                         'svc__C':[0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.5, 2.0, 10] , 'svc__class_weight':['balanced']}]\n",
    "\n",
    "    grid_search_item = GridSearchCV(estimator = svc,\n",
    "                              param_grid = parameters,\n",
    "                               cv =  cv,\n",
    "                               scoring = 'accuracy',\n",
    "                               n_jobs = -1)\n",
    "    grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "    print('Best scores and best parameters')\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true,y_pred))\n",
    "\n",
    "\n",
    "def GetLIWC(file:str): \n",
    "\tliwc = pd.read_csv(file)\n",
    "\tliwc = liwc.rename(columns = {liwc.columns[2]:'user_id'})\n",
    "\tliwcUser = liwc.groupby('user_id').mean().reset_index()\n",
    "\tliwcUser = liwcUser.drop(['Source (A)', 'Source (D)'], axis=1)\n",
    "\treturn liwcUser\n",
    "\n",
    "\n",
    "def mergeFea(features, liwc, empath): \n",
    "\tfeatures = pd.read_csv(features)\n",
    "\n",
    "\t#merge features\n",
    "\tliwcUser = GetLIWC(liwc)\n",
    "\tliwcUser2 = liwcUser.iloc[:,1::]\n",
    "\tliwcUser2.columns = [str(col) + '_liwc' for col in liwcUser2.columns]\n",
    "\tliwcUser2['user_id'] = liwcUser.user_id\n",
    "\n",
    "\tempath = pd.read_csv(empath)\n",
    "\tempath2 = empath.iloc[:,1::]\n",
    "\tempath2.columns = [str(col) + '_empath' for col in empath2.columns]\n",
    "\tempath2['user_id'] = empath.user_id\n",
    "\n",
    "\tallfea = pd.merge(features, liwcUser2, on = 'user_id', how = 'right')\n",
    "\tallfea = pd.merge(allfea, empath2, on = 'user_id', how = 'right')\n",
    "\treturn allfea\n",
    "\n",
    "def getCountVect(user_idFile, countVec):\n",
    "\ttext = pd.read_csv(user_idFile)\n",
    "\tcountVect = pd.read_csv(countVec)\n",
    "\tcountVect['user_id'] = text['user_id']\n",
    "\tcountVec2 = countVect.groupby(['user_id']).mean().reset_index()\n",
    "\treturn countVec2\n",
    "\n",
    "def featureUnionTest(selectFea, train_x, test_x):\n",
    "    #select trainset features\n",
    "    train_xSel = train_x.loc[:, train_x.columns.isin(selectFea)]\n",
    "    test_x2 = test_x.loc[:, test_x.columns.isin(train_xSel)]\n",
    "    test_x2['user_id'] = test_x.user_id\n",
    "    #remove not in testset\n",
    "    train_xSel = train_x.loc[:, train_x.columns.isin(test_x2.columns)]\n",
    "    train_xSel['user_id'] = train_x.user_id\n",
    "    #print('trainset and testset shape', train_x.shape, test_x.shape)\n",
    "    allfea = test_x2.append(train_xSel)\n",
    "    testSel = allfea[0:125]\n",
    "    return testSel\n",
    "    \n",
    "    \n",
    "def featureUnionTrain(selectFea, train_x, test_x):\n",
    "    #select trainset features\n",
    "    train_xSel = train_x.loc[:, train_x.columns.isin(selectFea)]\n",
    "    test_x2 = test_x.loc[:, test_x.columns.isin(train_xSel)]\n",
    "    test_x2['user_id'] = test_x.user_id\n",
    "    #remove not in testset\n",
    "    train_xSel = train_x.loc[:, train_x.columns.isin(test_x2.columns)]\n",
    "    train_xSel['user_id'] = train_x.user_id\n",
    "    #print('trainset and testset shape', train_x.shape, test_x.shape)\n",
    "    allfea = test_x2.append(train_xSel)\n",
    "    trainSel = allfea[125:621]\n",
    "    return trainSel\n",
    "\n",
    "\n",
    "def SVMPredictTestProb(X_train, y_train, X_test):\n",
    "    \n",
    "    smote_enn = SMOTEENN(random_state=42)\n",
    "    cv = StratifiedKFold(n_splits=5, random_state = 0)\n",
    "    svc = make_pipeline(StandardScaler(), svm.SVC(probability=True))\n",
    "    parameters = [{'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'svc__gamma': [0.01, 0.001, 0.0001],\n",
    "                         'svc__C':[0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.5, 2.0, 10] , 'svc__class_weight':['balanced']}]\n",
    "\n",
    "\n",
    "    grid_search_item = GridSearchCV(estimator = svc,\n",
    "                              param_grid = parameters,\n",
    "                               cv =  cv,\n",
    "                               scoring = 'accuracy',\n",
    "                               n_jobs = -1)\n",
    "    grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "    #y_pred = grid_search.predict(X_train)\n",
    "    #print(classification_report(y_train, y_pred))\n",
    "\n",
    "    print('Best scores and best parameters')\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    y_pred = grid_search.predict_proba(X_test)\n",
    "    X_test['classA'] = y_pred[:,0]\n",
    "    X_test['classB'] = y_pred[:,1]\n",
    "    X_test['classC'] = y_pred[:,2]\n",
    "    X_test['classD'] = y_pred[:,3]\n",
    "    ConfidenceS = X_test[['user_id', 'classA', 'classB', 'classC', 'classD']]\n",
    "\n",
    "    return ConfidenceS\n",
    "\n",
    "def SVMPredictTest(X_train, y_train, X_test):\n",
    "    \n",
    "    smote_enn = SMOTEENN(random_state=42)\n",
    "    cv = StratifiedKFold(n_splits=5, random_state = 0)\n",
    "    svc = make_pipeline(StandardScaler(), svm.SVC())\n",
    "    parameters = [{'svc__kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'svc__gamma': [0.01, 0.001, 0.0001],\n",
    "                         'svc__C':[0.1, 0.3, 0.5, 0.7, 0.9, 1.0, 1.5, 2.0, 10] , 'svc__class_weight':['balanced']}]\n",
    "\n",
    "\n",
    "    grid_search_item = GridSearchCV(estimator = svc,\n",
    "                              param_grid = parameters,\n",
    "                               cv =  cv,\n",
    "                               scoring = 'accuracy',\n",
    "                               n_jobs = -1)\n",
    "    grid_search = grid_search_item.fit(X_train, y_train)\n",
    "\n",
    "    #y_pred = grid_search.predict(X_train)\n",
    "    #print(classification_report(y_train, y_pred))\n",
    "\n",
    "    print('Best scores and best parameters')\n",
    "    print(grid_search.best_score_)\n",
    "    print(grid_search.best_params_)\n",
    "\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    test = X_test.copy()\n",
    "    test['predict_label_ML'] = y_pred\n",
    "    idResults = test[['user_id','predict_label_ML']]\n",
    "\n",
    "    return idResults\n",
    "\n",
    "\n",
    "def getConfidenceScore(resultProbablity,resultLabel):\n",
    "    resultFile = pd.merge(resultProbablity,resultLabel, on = 'user_id')\n",
    "    conScore = {}\n",
    "    for user, a, b, c, d, labels in zip(resultFile['user_id'], resultFile['classA'], resultFile['classB'], resultFile['classC'], resultFile['classD'], resultFile['predict_label_ML']):\n",
    "        if labels is 'a':\n",
    "            conScore[user] = a\n",
    "        elif labels is 'b':\n",
    "            conScore[user] = b\n",
    "        elif labels is 'c':\n",
    "            conScore[user] = c\n",
    "        elif labels is 'd':\n",
    "            conScore[user] = d\n",
    "    conScoredf = pd.DataFrame.from_dict(conScore, orient='index', columns = ['confidenceScore'])   \n",
    "    conScoredf['user_id'] = conScoredf.index\n",
    "    return conScoredf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 132) (125, 132)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:172: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:183: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:186: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "selectFeatures = selectFea(feaImp,500) \n",
    "test = featureUnionTest(selectFeatures, allfea3, allfeaTest)\n",
    "train = featureUnionTrain(selectFeatures, allfea3, allfeaTest)\n",
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(train.isnull().values.any())\n",
    "print(test.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/Users/lucia/phd_work/Clpsy/'\n",
    "path = '/home/lucia/phd_work/shareTask/'\n",
    "\n",
    "#merge features\n",
    "features = path + 'suicideDetection/features/FreqSentiMotiTopiFea.csv'\n",
    "liwc = path + 'suicideDetection/features/liwcSW.csv'\n",
    "empath = path + 'suicideDetection/features/empathSW.csv'\n",
    "allfea = mergeFea(features, liwc, empath)\n",
    "\n",
    "#select features and split train test\n",
    "X = allfea.iloc[:, 3:146]\n",
    "y = allfea.raw_label\n",
    "#y = y.replace(['a', 'b', 'c', 'd'], [1, 2, 2, 2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add count vect\n",
    "\n",
    "user_idFile = path + 'data/clpsych19_training_data/Btrain_NoNoise_SW.csv'\n",
    "countVec = path + 'countVec2.csv'\n",
    "countVec2 = getCountVect(user_idFile, countVec)\n",
    "#add tfidf count vect as features\n",
    "allfea = pd.merge(allfea, countVec2, on = 'user_id', how = 'right')\n",
    "\n",
    "y = allfea.raw_label\n",
    "# #y = y.replace(['a', 'b', 'c', 'd'], [1, 2, 2, 2]) \n",
    "allfea2 = allfea.iloc[:, 1::]\n",
    "allfea3 = allfea2.drop(['raw_label'],axis = 1)\n",
    "#allfea3 = allfea3.drop(['user_id'],axis = 1)\n",
    "# #RF Select feature\n",
    "#feaImp = RFfeatureSel(allfea3,y)\n",
    "feaImp = pd.read_csv(path + 'topFea.csv')\n",
    "#selectFea = selectFea(feaImp,200) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get test set\n",
      "(125, 329)\n",
      "(496, 329)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:168: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:171: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:185: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "print('get test set')\n",
    "featuresT = path + 'suicideDetection/TestFeatures/FreqSentiMotiTopiFea.csv'\n",
    "liwcT = path + 'suicideDetection/TestFeatures/liwcSW.csv'\n",
    "empathT = path + 'suicideDetection/TestFeatures/empathSW.csv'\n",
    "testFea = mergeFea(featuresT, liwcT, empathT)\n",
    "\n",
    "user_idFile = path + 'data/clpsych19_training_data/testSW.csv'\n",
    "countVec = path + 'suicideDetection/TestFeatures/countVec2.csv'\n",
    "countVec2 = getCountVect(user_idFile, countVec)\n",
    "#add tfidf count vect as features\n",
    "allfeaTest = pd.merge(testFea, countVec2, on = 'user_id', how = 'right')\n",
    "\n",
    "\n",
    "# selectedFeaTest = allfeaTest.loc[:, allfeaTest.columns.isin(selectFea)]\n",
    "# selectedFeaTest['user_id'] = allfeaTest.user_id\n",
    "#selectedFeaTest.to_csv(path + 'suicideDetection/TestFeatures/selectFeaTest.csv')\n",
    "\n",
    "#feature union \n",
    "# train = featureUnionTrain(selectedFeaX,selectedFeaTest)    \n",
    "# test = featureUnionTest(selectedFeaX,selectedFeaTest)\n",
    "# result = SVMPredictTest(train, y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:250: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.4012096774193548\n",
      "{'svc__C': 0.3, 'svc__class_weight': 'balanced', 'svc__gamma': 0.01, 'svc__kernel': 'sigmoid'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:405: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#get confidence score\n",
    "train = featureUnionTrain(selectedFeaX,selectedFeaTest)    \n",
    "test = featureUnionTest(selectedFeaX,selectedFeaTest)\n",
    "resultP = SVMPredictTestProb(train, y, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLresults = pd.merge(resultP, result, on = 'user_id')\n",
    "# MLresults.to_csv(path + '/data/clpsych19_training_data/testResultsCS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidenceScore</th>\n",
       "      <th>user_id</th>\n",
       "      <th>predict_label_ML</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575328</td>\n",
       "      <td>195.0</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.854208</td>\n",
       "      <td>450.0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidenceScore  user_id predict_label_ML\n",
       "0         0.575328    195.0                c\n",
       "1         0.854208    450.0                a"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conScoredf=getConfidenceScore(resultP, result)\n",
    "conScoredf2 = pd.merge(conScoredf, result, on = 'user_id')\n",
    "conScoredf2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "# test['predicted_labels_ML'] = result\n",
    "# idResults = test[['user_id','predicted_labels_ML']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmRe = pd.read_csv(path + '/data/clpsych19_training_data/testResults.csv')\n",
    "lmRe = pd.merge(lmRe, conScoredf2, on = 'user_id')\n",
    "lmRe.to_csv(path + '/data/clpsych19_training_data/testResultsBoth.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 125) (125, 125)\n",
      "Best scores and best parameters\n",
      "0.5446685878962536\n",
      "{'svc__C': 2.0, 'svc__class_weight': 'balanced', 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.65      0.74      0.69        35\n",
      "           b       0.67      0.22      0.33        18\n",
      "           c       0.25      0.28      0.26        32\n",
      "           d       0.60      0.62      0.61        64\n",
      "\n",
      "   micro avg       0.53      0.53      0.53       149\n",
      "   macro avg       0.54      0.47      0.48       149\n",
      "weighted avg       0.54      0.53      0.52       149\n",
      "\n",
      "[[26  0  6  3]\n",
      " [ 6  4  3  5]\n",
      " [ 3  1  9 19]\n",
      " [ 5  1 18 40]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#top 300 features\n",
    "selectFeatures = selectFea(feaImp,400)\n",
    "test = featureUnionTest(selectFeatures, allfea3, allfeaTest)\n",
    "train = featureUnionTrain(selectFeatures, allfea3,400, allfeaTest)\n",
    "print(train.shape,test.shape)\n",
    "resultN = SVMclassifier(train, y) #train without manual features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:184: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 125) (125, 125)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:349: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.5201612903225806\n",
      "{'svc__C': 0.9, 'svc__class_weight': 'balanced', 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/lucia/anaconda3/lib/python3.6/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best scores and best parameters\n",
      "0.5201612903225806\n",
      "{'svc__C': 0.9, 'svc__class_weight': 'balanced', 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "(496, 125) (125, 129)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucia/anaconda3/lib/python3.6/site-packages/imblearn/pipeline.py:405: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "selectFeatures = selectFea(feaImp,400) \n",
    "test = featureUnionTest(selectFeatures, allfea3, allfeaTest)\n",
    "train = featureUnionTrain(selectFeatures, allfea3, allfeaTest)\n",
    "print(train.shape,test.shape)\n",
    "#resultN = SVMclassifier(train, y) #just testing with train set\n",
    "result = SVMPredictTest(train, y, test)#train labels\n",
    "resultP = SVMPredictTestProb(train, y, test) #train confidence scores\n",
    "print(train.shape,test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compare with LM results\n",
    "#merge confidence score\n",
    "conScoredf=getConfidenceScore(resultP, result)\n",
    "conScoredf2 = pd.merge(conScoredf, result, on = 'user_id')\n",
    "lmRe = pd.read_csv(path + '/data/clpsych19_training_data/testResults.csv')\n",
    "lmRe = pd.merge(lmRe, conScoredf2, on = 'user_id')\n",
    "lmRe.to_csv(path + '/data/clpsych19_training_data/testResultsBoth3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    83\n",
      "a    54\n",
      "c    37\n",
      "b    12\n",
      "Name: predict_label_ML, dtype: int64\n",
      "a    47\n",
      "d    40\n",
      "c    29\n",
      "b     9\n",
      "Name: predict_label_ML, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(lmRe.predict_label_ML.value_counts())\n",
    "NoDup = lmRe.drop_duplicates(subset='user_id', keep=\"last\")\n",
    "print(NoDup.predict_label_ML.value_counts())\n",
    "NoDup = NoDup[['user_id','predict_label_ML','confidenceScore']]\n",
    "NoDup.to_csv(path + '/suicideDetection/results/MachineLearningModel.csv',header=None,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We seem to find that the ML model compensate the LM model in class A, so this classifer is to convert class A with low confidence score to the ML model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 41, 'b': 20, 'c': 25, 'd': 39})"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "newLabel = {}\n",
    "for user, conScore, LanMLab, MaLab in zip(lmRe['userid'], lmRe['confidenceScore'], lmRe['predicted_label'], lmRe['predict_label_ML']):\n",
    "    if MaLab is 'a' and conScore < 0.40:      \n",
    "        newLabel[user] =  LanMLab\n",
    "    if LanMLab is 'b':\n",
    "        newLabel[user] = LanMLab\n",
    "    else:\n",
    "        newLabel[user] = MaLab\n",
    "\n",
    "Counter(newLabel.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "HybridModel = pd.DataFrame.from_dict(newLabel, orient='index', columns = ['label']) \n",
    "HybridModel['userid'] = HybridModel.index\n",
    "HybridModel = HybridModel[['userid','label']]\n",
    "HybridModel.to_csv(path + '/suicideDetection/results/HybriedModel.csv',header=None,index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
